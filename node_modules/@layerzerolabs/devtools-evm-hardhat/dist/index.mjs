import 'hardhat/types/config';
import pMemoize2 from 'p-memoize';
import { Contract } from '@ethersproject/contracts';
import { makeZeroAddress, createContractErrorParser, isEVMAddress, omniContractToPoint, connectOmniContract, createAnvilCliOptions, OmniSignerEVM, GnosisOmniSignerEVM } from '@layerzerolabs/devtools-evm';
import { HardhatContext } from 'hardhat/internal/context';
import { Environment } from 'hardhat/internal/core/runtime-environment';
import { formatEid, EndpointIdSchema, OmniPointSchema, splitCommaSeparated, isOmniPoint, parallel, OmniGraphBuilder, formatOmniTransaction as formatOmniTransaction$1 } from '@layerzerolabs/devtools';
import { EthersProviderWrapper } from '@nomiclabs/hardhat-ethers/internal/ethers-provider-wrapper';
import assert, { AssertionError } from 'assert';
import memoize from 'micro-memoize';
import { types as types$1, subtask, task } from 'hardhat/config';
import { Artifacts } from 'hardhat/internal/artifacts';
import { HardhatError } from 'hardhat/internal/core/errors';
import { ERRORS } from 'hardhat/internal/core/errors-list';
import { isLogLevel, createModuleLogger } from '@layerzerolabs/io-devtools';
import { endpointIdToNetwork, Environment as Environment$1, Stage } from '@layerzerolabs/lz-definitions';
import 'hardhat-deploy/dist/src/type-extensions';
import { join, resolve, dirname } from 'path';
import { z } from 'zod';
import { pipe } from 'fp-ts/lib/function';
import * as RR from 'fp-ts/ReadonlyRecord';
import * as R from 'fp-ts/Record';

var __require = /* @__PURE__ */ ((x) => typeof require !== "undefined" ? require : typeof Proxy !== "undefined" ? new Proxy(x, {
  get: (a, b) => (typeof require !== "undefined" ? require : a)[b]
}) : x)(function(x) {
  if (typeof require !== "undefined")
    return require.apply(this, arguments);
  throw Error('Dynamic require of "' + x + '" is not supported');
});

// src/errors/errors.ts
var ConfigurationError = class extends Error {
};
var createCombinedContract = pMemoize2(async () => {
  const artifacts = await getAllArtifacts();
  const abi = artifacts.flatMap((artifact) => artifact.abi).filter(isErrorFragment);
  const deduplicatedAbi = Object.values(Object.fromEntries(abi.map((abi2) => [JSON.stringify(abi2), abi2])));
  return { eid: -1, contract: new Contract(makeZeroAddress(), deduplicatedAbi) };
});
var createErrorParser = async () => createContractErrorParser(await createCombinedContract());
var getDefaultContext = () => {
  try {
    return HardhatContext.getHardhatContext();
  } catch (error) {
    throw new ConfigurationError(`Could not get Hardhat context: ${error}`);
  }
};
var getDefaultRuntimeEnvironment = () => {
  const context = getDefaultContext();
  try {
    return context.getHardhatRuntimeEnvironment();
  } catch (error) {
    throw new ConfigurationError(`Could not get Hardhat Runtime Environment: ${error}`);
  }
};
var getHreByNetworkName = pMemoize2(async (networkName) => {
  const context = getDefaultContext();
  const environment2 = getDefaultRuntimeEnvironment();
  try {
    return new Environment(
      environment2.config,
      {
        ...environment2.hardhatArguments,
        network: networkName
      },
      environment2.tasks,
      environment2.scopes,
      context.environmentExtenders,
      context.experimentalHardhatNetworkMessageTraceHooks,
      environment2.userConfig,
      context.providerExtenders
      // This is a bit annoying - the environmentExtenders are not stronly typed
      // so TypeScript complains that the properties required by HardhatRuntimeEnvironment
      // are not present on HardhatRuntimeEnvironmentImplementation
    );
  } catch (error) {
    throw new ConfigurationError(`Could not setup Hardhat Runtime Environment: ${error}`);
  }
});
var createGetHreByEid = (hre = getDefaultRuntimeEnvironment()) => pMemoize2(async (eid) => getHreByNetworkName(getNetworkNameForEid(eid, hre)));
var wrapEIP1193Provider = (provider) => new EthersProviderWrapper(provider);
var getEidForNetworkName = (networkName, hre = getDefaultRuntimeEnvironment()) => {
  const networkConfig = hre.config.networks[networkName];
  assert(networkConfig, `Network '${networkName}' is not defined in hardhat config`);
  assert(networkConfig.eid != null, `Network '${networkName}' does not have 'eid' property defined in its config`);
  return networkConfig.eid;
};
var getNetworkNameForEid = (eid, hre = getDefaultRuntimeEnvironment()) => {
  const eidsByNetworkName = getEidsByNetworkName(hre);
  for (const [networkName, networkEid] of Object.entries(eidsByNetworkName)) {
    if (networkEid === eid) {
      return networkName;
    }
  }
  assert(false, `Could not find a network for eid ${eid} (${formatEid(eid)})`);
};
var getEidsByNetworkName = memoize(
  (hre = getDefaultRuntimeEnvironment()) => {
    const networkEntries = Object.entries(hre.config.networks);
    const eidEntries = networkEntries.map(
      ([networkName, networkConfig]) => [networkName, networkConfig.eid]
    );
    const eidsByNetworkName = Object.fromEntries(eidEntries);
    const eidEntriesWithDefinedEid = eidEntries.filter(([_, eid]) => eid != null);
    const definedEidsByNetworkName = Object.fromEntries(eidEntriesWithDefinedEid);
    const allDefinedEids = new Set(Object.values(definedEidsByNetworkName));
    const allNetworkNames = new Set(Object.keys(definedEidsByNetworkName));
    if (allDefinedEids.size === allNetworkNames.size) {
      return eidsByNetworkName;
    }
    const duplicatedNetworkNames = Array.from(allDefinedEids).map(
      (eid) => eidEntriesWithDefinedEid.flatMap(
        ([networkName, definedEid]) => eid === definedEid ? [networkName] : []
      )
    ).filter((networkNames) => networkNames.length > 1);
    const messages = duplicatedNetworkNames.map(
      (networkNames) => `- ${networkNames.join(", ")} have eid set to ${formatEid(eidsByNetworkName[networkNames[0]])}`
    ).join("\n");
    throw new Error(
      `Found multiple networks configured with the same 'eid':

${messages}

Please fix this in your hardhat config.`
    );
  }
);
var inheritTask = (parentTaskName, context = getDefaultContext()) => (taskName) => {
  const parentTaskDefinition = context.tasksDSL.getTaskDefinition(void 0, parentTaskName);
  assert(parentTaskDefinition != null, `Missing task definition for ${parentTaskName}`);
  const creator = parentTaskDefinition.isSubtask ? subtask : task;
  const childTask = creator(taskName).setAction(parentTaskDefinition.action);
  if (parentTaskDefinition.description != null) {
    childTask.setDescription(parentTaskDefinition.description);
  }
  for (const definition of Object.values(parentTaskDefinition.paramDefinitions)) {
    if (definition.isFlag) {
      childTask.addFlag(definition.name, definition.description);
    } else {
      childTask.addParam(
        definition.name,
        definition.description,
        definition.defaultValue,
        definition.type,
        definition.isOptional
      );
    }
  }
  for (const definition of parentTaskDefinition.positionalParamDefinitions) {
    if (definition.isVariadic) {
      childTask.addVariadicPositionalParam(
        definition.name,
        definition.description,
        definition.defaultValue,
        definition.type,
        definition.isOptional
      );
    } else {
      childTask.addPositionalParam(
        definition.name,
        definition.description,
        definition.defaultValue,
        definition.type,
        definition.isOptional
      );
    }
  }
  return childTask;
};
var getAllArtifacts = pMemoize2(async (hre = getDefaultRuntimeEnvironment()) => {
  var _a, _b;
  const externalContracts = (_b = (_a = hre.config.external) == null ? void 0 : _a.contracts) != null ? _b : [];
  const artifactsPaths = [
    hre.config.paths.artifacts,
    hre.config.paths.imports,
    ...externalContracts.flatMap(({ artifacts }) => artifacts)
  ];
  const artifactsObjects = artifactsPaths.map((path) => new Artifacts(path));
  const artifactses = await Promise.all(artifactsObjects.map(getAllArtifactsFrom));
  return artifactses.flat();
});
var getAllArtifactsFrom = async (artifactsObject) => {
  const fullyQualifiedNames = await artifactsObject.getAllFullyQualifiedNames();
  return fullyQualifiedNames.map((name) => artifactsObject.readArtifactSync(name));
};
var isErrorFragment = (fragment) => fragment.type === "error";
var csv = {
  name: "csv",
  parse(name, value) {
    return splitCommaSeparated(value);
  },
  validate() {
  }
};
var isEnvironment = (value) => Object.values(Environment$1).includes(value);
var environment = {
  name: "environment",
  parse(name, value) {
    if (!isEnvironment(value)) {
      throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {
        value,
        name,
        type: "environment"
      });
    }
    return value;
  },
  validate() {
  }
};
var isStage = (value) => Object.values(Stage).includes(value);
var stage = {
  name: "stage",
  parse(name, value) {
    if (!isStage(value)) {
      throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {
        value,
        name,
        type: "stage"
      });
    }
    return value;
  },
  validate() {
  }
};
var logLevel = {
  name: "logLevel",
  parse(name, value) {
    if (!isLogLevel(value)) {
      throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {
        value,
        name,
        type: "logLevel"
      });
    }
    return value;
  },
  validate() {
  }
};
var fn = {
  name: "function",
  parse: (argName, value) => {
    if (typeof value !== "function") {
      throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {
        value,
        name: argName,
        type: fn.name
      });
    }
    return value;
  },
  validate() {
  }
};
var signer = {
  name: "signer",
  parse: (argName, value) => {
    if (isEVMAddress(value)) {
      return { type: "address", address: value };
    }
    const parsed = parseInt(value, 10);
    if (!isNaN(parsed)) {
      if (parsed < 0) {
        throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {
          value,
          name: argName,
          type: signer.name
        });
      }
      return { type: "index", index: parsed };
    }
    return { type: "named", name: value };
  },
  validate() {
  }
};
var types = { csv, logLevel, fn, signer, environment, stage, ...types$1 };
var resolvePackageDirectory = (packageName) => {
  const packageJsonName = join(packageName, "package.json");
  const packageJsonPath = __require.resolve(packageJsonName);
  return dirname(packageJsonPath);
};
var withLayerZeroDeployments = (...packageNames) => {
  const resolvedDeploymentsDirectories = packageNames.map(resolvePackageDirectory).map((resolvedPackagePath) => join(resolvedPackagePath, "deployments"));
  return (config) => {
    var _a;
    return {
      ...config,
      external: {
        ...config.external,
        // Now for the meat of the operation, we'll enrich the external.deployments object
        deployments: Object.fromEntries(
          Object.entries((_a = config.networks) != null ? _a : {}).flatMap(([networkName, networkConfig]) => {
            var _a2, _b, _c;
            const eid = networkConfig == null ? void 0 : networkConfig.eid;
            const networkLogger = createModuleLogger(networkName);
            if (eid == null) {
              networkLogger.debug(
                "Endpoint ID not specified in hardhat config, skipping external deployment configuration"
              );
              return [];
            }
            try {
              const layerZeroNetworkName = endpointIdToNetwork(eid, networkConfig == null ? void 0 : networkConfig.isLocalEid);
              const layerZeroNetworkDeploymentsDirectories = resolvedDeploymentsDirectories.map(
                (deploymentsDirectory) => join(deploymentsDirectory, layerZeroNetworkName)
              );
              return [
                [
                  // The external deployments object is keyed by local network names
                  // which do not necessarily match the LayerZero ones
                  networkName,
                  // And its values are arrays of filesystem paths referring to individual network deployment directories
                  Array.from(
                    // Since we want the paths to be unique, we'll put everything we have into a Set, then convert back to array
                    /* @__PURE__ */ new Set([
                      // These are the external deployments already configured
                      ...(_c = (_b = (_a2 = config.external) == null ? void 0 : _a2.deployments) == null ? void 0 : _b[networkName]) != null ? _c : [],
                      // And these are the new ones
                      ...layerZeroNetworkDeploymentsDirectories
                    ])
                  )
                ]
              ];
            } catch (error) {
              networkLogger.error(
                `Invalid endpoint ID specified in hardhat config (${eid}), skipping external deployment configuration`
              );
              return [];
            }
          })
        )
      }
    };
  };
};
var withLayerZeroArtifacts = (...packageNames) => {
  const resolvedArtifactsDirectories = packageNames.map(resolvePackageDirectory).map((resolvedPackagePath) => join(resolvedPackagePath, "artifacts"));
  return (config) => {
    var _a, _b, _c, _d, _e;
    const existingArtifacts = new Set((_c = (_b = (_a = config.external) == null ? void 0 : _a.contracts) == null ? void 0 : _b.flatMap(({ artifacts }) => artifacts)) != null ? _c : []);
    const newArtifacts = new Set(
      resolvedArtifactsDirectories.filter((artifact) => !existingArtifacts.has(artifact))
    );
    if (newArtifacts.size === 0) {
      return config;
    }
    return {
      ...config,
      external: {
        ...config.external,
        contracts: [
          ...(_e = (_d = config.external) == null ? void 0 : _d.contracts) != null ? _e : [],
          {
            artifacts: Array.from(newArtifacts)
          }
        ]
      }
    };
  };
};

// src/constants/tasks.ts
var TASK_LZ_DEPLOY = "lz:deploy";
var TASK_LZ_EXPORT_DEPLOYMENTS_TYPESCRIPT = "lz:export:deployments:typescript";
var SUBTASK_LZ_SIGN_AND_SEND = "::lz:sign-and-send";
var TASK_LZ_TEST_SIMULATION_START = "lz:test:simulation:start";
var TASK_LZ_TEST_SIMULATION_LOGS = "lz:test:simulation:logs";
var TASK_LZ_TEST_SIMULATION_STOP = "lz:test:simulation:stop";
function assertHardhatDeploy(hre) {
  assert(hre.deployments, `You don't seem to be using hardhat-deploy in your project`);
}
function assertDefinedNetworks(networkNames, hre = getDefaultRuntimeEnvironment()) {
  const definedNetworkNames = new Set(Object.keys(getEidsByNetworkName(hre)));
  for (const networkName of networkNames) {
    if (definedNetworkNames.has(networkName)) {
      continue;
    }
    throw new AssertionError({
      message: `Network '${networkName}' has not been defined. Defined networks are ${Array.from(definedNetworkNames).join(", ")}`
    });
  }
  return networkNames;
}
var omniDeploymentToPoint = ({ eid, deployment }) => ({
  eid,
  address: deployment.address
});
var omniDeploymentToContract = ({ eid, deployment }) => ({
  eid,
  contract: new Contract(deployment.address, deployment.abi)
});
var createContractFactory = (environmentFactory = createGetHreByEid()) => {
  return pMemoize2(async ({ eid, address, contractName }) => {
    const env = await environmentFactory(eid);
    assertHardhatDeploy(env);
    if (contractName != null && address != null) {
      const artifact = await env.deployments.getArtifact(contractName);
      const contract = new Contract(address, artifact.abi);
      return { eid, contract };
    }
    if (contractName != null && address == null) {
      const deployment = await env.deployments.getOrNull(contractName);
      assert(deployment != null, `Could not find a deployment for contract '${contractName}'`);
      return omniDeploymentToContract({ eid, deployment });
    }
    if (address != null) {
      await env.deployments.all();
      const deployments = await env.deployments.getDeploymentsFromAddress(address);
      assert(deployments.length > 0, `Could not find a deployment for address '${address}'`);
      const mergedAbis = deployments.flatMap((deployment) => deployment.abi);
      const deduplicatedAbi = Object.values(
        Object.fromEntries(mergedAbis.map((abi) => [JSON.stringify(abi), abi]))
      );
      return { eid, contract: new Contract(address, deduplicatedAbi) };
    }
    assert(false, "At least one of contractName, address must be specified for OmniPointHardhat");
  });
};
var createOmniPointHardhatTransformer = (contractFactory = createContractFactory()) => async (point) => isOmniPoint(point) ? point : omniContractToPoint(await contractFactory(point));
var createOmniNodeHardhatTransformer = (pointTransformer = createOmniPointHardhatTransformer()) => async ({ contract, config }) => ({
  point: await pointTransformer(contract),
  config
});
var createOmniEdgeHardhatTransformer = (pointTransformer = createOmniPointHardhatTransformer()) => async ({ from, to, config }) => ({
  vector: {
    from: await pointTransformer(from),
    to: await pointTransformer(to)
  },
  config
});
var createOmniGraphHardhatTransformer = (nodeTransformer = createOmniNodeHardhatTransformer(), edgeTransformer = createOmniEdgeHardhatTransformer(), applicative = parallel) => async ({ contracts, connections }) => ({
  contracts: await applicative(contracts.map((contract) => () => nodeTransformer(contract))),
  connections: await applicative(connections.map((connection) => () => edgeTransformer(connection)))
});

// src/omnigraph/builder.ts
var OmniGraphBuilderHardhat = class {
  static async fromConfig(graph, transform = createOmniGraphHardhatTransformer()) {
    return OmniGraphBuilder.fromGraph(await transform(graph));
  }
  constructor() {
    assert(
      false,
      "OmniGraphBuilderHardhat cannot be instantiated - it only provides static utilities for working with OmniGraph"
    );
  }
};
var createProviderFactory = (networkEnvironmentFactory = createGetHreByEid()) => {
  return pMemoize2(async (eid) => {
    const env = await networkEnvironmentFactory(eid);
    return wrapEIP1193Provider(env.network.provider);
  });
};

// src/omnigraph/contracts.ts
var createConnectedContractFactory = (contractFactory = createContractFactory(), providerFactory = createProviderFactory()) => pMemoize2(async (point) => {
  const contract = await contractFactory(point);
  const provider = await providerFactory(point.eid);
  return connectOmniContract(contract, provider);
});
var OmniPointHardhatSchema = z.object({
  eid: EndpointIdSchema,
  contractName: z.string().nullish(),
  address: z.string().nullish()
});
var OmniPointOrOmniPointHardhatSchema = z.union([OmniPointHardhatSchema, OmniPointSchema]);
var createOmniNodeHardhatSchema = (configSchema) => z.object({
  contract: OmniPointOrOmniPointHardhatSchema,
  config: configSchema
});
var createOmniEdgeHardhatSchema = (configSchema) => z.object({
  from: OmniPointOrOmniPointHardhatSchema,
  to: OmniPointOrOmniPointHardhatSchema,
  config: configSchema
});
var createOmniGraphHardhatSchema = (nodeSchema, edgeSchema) => z.object({
  contracts: z.array(nodeSchema),
  connections: z.array(edgeSchema)
});
var hasContractName = (value) => "contractName" in value && typeof value.contractName === "string";
var createEvmNodeServiceSpec = (anvilOptions) => ({
  // This service references a Dockerfile that is copied
  // next to the resulting docker-compose.yaml
  //
  // The source for this Dockerfile is located in src/simulation/assets/Dockerfile.conf
  build: {
    dockerfile: "Dockerfile",
    target: "node-evm"
  },
  command: ["anvil", ...createAnvilCliOptions(anvilOptions)]
});
var createEvmNodeProxyServiceSpec = (port, networkServices) => ({
  // This service references a Dockerfile that is copied
  // next to the resulting docker-compose.yaml
  //
  // The source for this Dockerfile is located in src/simulation/assets/Dockerfile.conf
  build: {
    dockerfile: "Dockerfile",
    target: "proxy-evm"
  },
  // This service will expose its internal 8545 port to a host port
  //
  // The internal 8545 port is hardcoded both here and in the nginx.conf file,
  // the source for which is located in src/simulation/assets/nginx.conf
  ports: [`${port}:8545`],
  depends_on: pipe(
    networkServices,
    // This service will depend on the RPCs to be healthy
    // so we'll take the networkServices object and replace
    // the values with service_healthy condition
    RR.map(() => ({
      condition: "service_healthy"
    }))
  )
});
var createSimulationComposeSpec = (config, networks) => ({
  version: "3.9",
  services: pipe(
    networks,
    // First we turn the networks into docker compose specs for EVM nodes
    RR.map(createEvmNodeServiceSpec),
    (networkServiceSpecs) => (
      // Then we add the RPC proxy server
      //
      // There is a small edge case here that we can address
      // if it ever comes up: if a network is called 'rpc', this compose file
      // will not work.
      //
      // The fix for this is to prefix all networks with something like network-xxx
      // but we can do that if ever this usecase comes up
      pipe(
        networkServiceSpecs,
        RR.upsertAt("rpc", createEvmNodeProxyServiceSpec(config.port, networkServiceSpecs))
      )
    )
  )
});
var resolveSimulationConfig = (userConfig, hardhatConfig) => {
  var _a, _b;
  return {
    port: (_a = userConfig.port) != null ? _a : 8545,
    directory: resolve(hardhatConfig.paths.root, (_b = userConfig.directory) != null ? _b : ".layerzero"),
    anvil: {
      // For now we'll hardcode the mnemonic we'll use to seed the accounts on the simulation networks
      mnemonic: "test test test test test test test test test test test junk",
      ...userConfig.anvil,
      // The host and port need to always point to 0.0.0.0:8545
      // since anvil runs in the container that exposes this port on 0.0.0.0
      host: "0.0.0.0",
      port: 8545
    }
  };
};
var getAnvilOptionsFromHardhatNetworks = (config, networksConfig) => pipe(
  networksConfig,
  // We want to drop all the networks that don't have URLs
  R.filter(isHttpNetworkConfig),
  // And map the network configs into AnvilOptions
  R.map(
    (networkConfig) => ({
      ...config.anvil,
      forkUrl: networkConfig.url
    })
  )
);
var getHardhatNetworkOverrides = (config, networksConfig) => pipe(
  networksConfig,
  // We want to drop all the networks that don't have URLs
  R.filter(isHttpNetworkConfig),
  // We'll take the existing network configs and point them to our RPC proxy
  //
  // It's important that these configs are not saved to filesystem as they might contain
  // sensitive data (and forgetting to ignore these files in git could lead to security breaches)
  R.mapWithIndex(
    (networkName, networkConfig) => {
      var _a, _b;
      return {
        ...networkConfig,
        // We want to redirect this network to the local proxy
        //
        // This is the nginx server listening on the port we configured in the simulation configuration
        url: new URL(networkName, `http://localhost:${config.port}`).toString(),
        // For now the mnemonic in identical for all the networks and comes
        // from the simulation configuration
        //
        // In future we could respect the mnemonics set in the original hardhat config
        // but that comes with complexities:
        //
        // - Some networks / hardhat configs will not be using mnemonics
        // - We don't want to be throwing production mnemonics around and storing them in json files
        accounts: {
          mnemonic: config.anvil.mnemonic,
          // These need to be defaulted to the anvil options
          // (or the anvil defaults)
          //
          // See https://book.getfoundry.sh/reference/cli/anvil for anvil defaults
          count: (_a = config.anvil.count) != null ? _a : 10,
          path: (_b = config.anvil.derivationPath) != null ? _b : "m/44'/60'/0'/0/",
          // These will be hardcoded for now as anvil does not support setting these
          initialIndex: 0,
          passphrase: ""
        }
      };
    }
  )
);
var pickNetworkConfigs = (networks) => R.filterWithIndex((networkName) => networks.includes(networkName));
var isHttpNetworkConfig = (networkConfig) => "url" in networkConfig && typeof networkConfig.url === "string";
var formatOmniTransaction = (transaction) => ({
  Network: getNetworkNameForEid(transaction.point.eid),
  ...formatOmniTransaction$1(transaction)
});
var createSignerFactory = (definition, networkEnvironmentFactory = createGetHreByEid(), providerFactory = createProviderFactory(networkEnvironmentFactory), signerAddressorIndexFactory = createSignerAddressOrIndexFactory(definition, networkEnvironmentFactory)) => {
  return pMemoize2(async (eid) => {
    const provider = await providerFactory(eid);
    const addressOrIndex = await signerAddressorIndexFactory(eid);
    const signer2 = provider.getSigner(addressOrIndex);
    return new OmniSignerEVM(eid, signer2);
  });
};
var createGnosisSignerFactory = (definition, networkEnvironmentFactory = createGetHreByEid(), providerFactory = createProviderFactory(networkEnvironmentFactory), signerAddressorIndexFactory = createSignerAddressOrIndexFactory(definition, networkEnvironmentFactory)) => {
  return pMemoize2(async (eid) => {
    const provider = await providerFactory(eid);
    const addressOrIndex = await signerAddressorIndexFactory(eid);
    const signer2 = provider.getSigner(addressOrIndex);
    const env = await networkEnvironmentFactory(eid);
    const safeConfig = env.network.config.safeConfig;
    if (!safeConfig) {
      throw new Error("No safe config found for the current network");
    }
    return new GnosisOmniSignerEVM(eid, signer2, safeConfig.safeUrl, safeConfig);
  });
};
var createSignerAddressOrIndexFactory = (definition, networkEnvironmentFactory = createGetHreByEid()) => async (eid) => {
  if (definition == null) {
    return void 0;
  }
  if (definition.type === "address") {
    return definition.address;
  }
  if (definition.type === "index") {
    return definition.index;
  }
  const hre = await networkEnvironmentFactory(eid);
  const accounts = await hre.getNamedAccounts();
  const account = accounts[definition.name];
  assert(account != null, `Missing named account '${definition.name}' for eid ${formatEid(eid)}`);
  return account;
};

export { ConfigurationError, OmniGraphBuilderHardhat, OmniPointHardhatSchema, SUBTASK_LZ_SIGN_AND_SEND, TASK_LZ_DEPLOY, TASK_LZ_EXPORT_DEPLOYMENTS_TYPESCRIPT, TASK_LZ_TEST_SIMULATION_LOGS, TASK_LZ_TEST_SIMULATION_START, TASK_LZ_TEST_SIMULATION_STOP, assertDefinedNetworks, assertHardhatDeploy, createConnectedContractFactory, createContractFactory, createErrorParser, createEvmNodeProxyServiceSpec, createEvmNodeServiceSpec, createGetHreByEid, createGnosisSignerFactory, createOmniEdgeHardhatSchema, createOmniEdgeHardhatTransformer, createOmniGraphHardhatSchema, createOmniGraphHardhatTransformer, createOmniNodeHardhatSchema, createOmniNodeHardhatTransformer, createOmniPointHardhatTransformer, createProviderFactory, createSignerAddressOrIndexFactory, createSignerFactory, createSimulationComposeSpec, fn, formatOmniTransaction, getAllArtifacts, getAnvilOptionsFromHardhatNetworks, getDefaultContext, getDefaultRuntimeEnvironment, getEidForNetworkName, getEidsByNetworkName, getHardhatNetworkOverrides, getHreByNetworkName, getNetworkNameForEid, hasContractName, inheritTask, isErrorFragment, omniDeploymentToContract, omniDeploymentToPoint, pickNetworkConfigs, resolveSimulationConfig, signer, types, withLayerZeroArtifacts, withLayerZeroDeployments, wrapEIP1193Provider };
//# sourceMappingURL=out.js.map
//# sourceMappingURL=index.mjs.map