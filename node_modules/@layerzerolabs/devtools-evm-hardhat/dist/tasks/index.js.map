{"version":3,"sources":["../../src/tasks/deploy.ts","../../src/constants/tasks.ts","../../src/runtime.ts","../../src/errors/errors.ts","../../src/artifacts.ts","../../src/errors/parser.ts","../../src/cli.ts","../../src/internal/assertions.ts","../../src/type-extensions.ts","../../src/tasks/simulation/logs.ts","../../src/simulation/config.ts","../../src/tasks/simulation/start.ts","../../src/simulation/compose.ts","../../src/simulation/assets/Dockerfile.conf","../../src/simulation/assets/nginx.conf","../../src/tasks/simulation/stop.ts","../../src/transactions/format.ts","../../src/tasks/transactions/subtask.sign-and-send.ts","../../src/tasks/export.deployments.typescript.ts"],"names":["task","formatEid","pMemoize","abi","environment","assert","splitCommaSeparated","logLevel","stage","printLogo","createLogger","setDefaultLogLevel","action","printJson","join","pipe","spawnSync","isFile","pluralizeNoun","printBoolean","promptToContinue","createProgressBar","printRecords","render","subtask"],"mappings":";AAAA,SAAS,QAAAA,aAAY;AAErB,SAAS,oBAAoB;;;ACFtB,IAAM,iBAAiB;AAEvB,IAAM,wCAAwC;AAE9C,IAAM,2BAA2B;AAEjC,IAAM,gCAAgC;AAEtC,IAAM,+BAA+B;AAErC,IAAM,+BAA+B;;;ADN5C;AAAA,EAEI;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,OACG;AAEP,SAAS,mBAAmB,WAAW,cAAc,cAAc;AACnE,SAAS,aAAAC,kBAAiB;;;AEb1B,OAAOC,eAAc;;;ACAd,IAAM,qBAAN,cAAiC,MAAM;AAAC;;;ACD/C,SAAS,iBAAiB;AAE1B,OAAO,cAAc;AAOd,IAAM,kBAAkB,SAAS,OAAO,MAAM,6BAA6B,MAA2B;AAV7G;AAcI,QAAM,qBAAoB,eAAI,OAAO,aAAX,mBAAqB,cAArB,YAAkC,CAAC;AAC7D,QAAM,iBAA2B;AAAA,IAC7B,IAAI,OAAO,MAAM;AAAA,IACjB,IAAI,OAAO,MAAM;AAAA,IACjB,GAAG,kBAAkB,QAAQ,CAAC,EAAE,UAAU,MAAM,SAAS;AAAA,EAC7D;AAGA,QAAM,mBAAmB,eAAe,IAAI,CAAC,SAAS,IAAI,UAAU,IAAI,CAAC;AAGzE,QAAM,cAAc,MAAM,QAAQ,IAAI,iBAAiB,IAAI,mBAAmB,CAAC;AAE/E,SAAO,YAAY,KAAK;AAC5B,CAAC;AAED,IAAM,sBAAsB,OAAO,oBAA+B;AAE9D,QAAM,sBAAsB,MAAM,gBAAgB,0BAA0B;AAE5E,SAAO,oBAAoB,IAAI,CAAC,SAAS,gBAAgB,iBAAiB,IAAI,CAAC;AACnF;AAEO,IAAM,kBAAkB,CAC3B,aAC4C,SAAS,SAAS;;;ACtClE,SAAS,gBAAgB;AACzB,SAAuB,iCAAiC;AACxD,SAAS,uBAAuB;AAEhC,OAAOA,eAAc;AAQrB,IAAM,yBAAyBA,UAAS,YAAmC;AAEvE,QAAM,YAAY,MAAM,gBAAgB;AAGxC,QAAM,MAAM,UAAU,QAAQ,CAAC,aAAa,SAAS,GAAG,EAAE,OAAO,eAAe;AAIhF,QAAM,kBAAkB,OAAO,OAAO,OAAO,YAAY,IAAI,IAAI,CAACC,SAAQ,CAAC,KAAK,UAAUA,IAAG,GAAGA,IAAG,CAAC,CAAC,CAAC;AAItG,SAAO,EAAE,KAAK,IAAkB,UAAU,IAAI,SAAS,gBAAgB,GAAG,eAAe,EAAE;AAC/F,CAAC;;;AHtBD,SAAS,sBAAsB;AAC/B,SAAS,eAAe,+CAA+C;AAEvE,SAAwC,iBAAiB;AACzD,SAAS,6BAA6B;AACtC,OAAO,YAAY;AACnB,OAAO,aAAa;AACpB,SAAS,SAAS,YAAY;AAoBvB,IAAM,oBAAoB,MAAsB;AAMnD,MAAI;AACA,WAAO,eAAe,kBAAkB;AAAA,EAC5C,SAAS,OAAgB;AACrB,UAAM,IAAI,mBAAmB,kCAAkC,KAAK,EAAE;AAAA,EAC1E;AACJ;AASO,IAAM,+BAA+B,MAAiC;AAEzE,QAAM,UAAU,kBAAkB;AAMlC,MAAI;AACA,WAAO,QAAQ,6BAA6B;AAAA,EAChD,SAAS,OAAgB;AACrB,UAAM,IAAI,mBAAmB,8CAA8C,KAAK,EAAE;AAAA,EACtF;AACJ;AAcO,IAAM,sBAA+DD,UAAS,OAAO,gBAAgB;AACxG,QAAM,UAAU,kBAAkB;AAClC,QAAME,eAAc,6BAA6B;AAEjD,MAAI;AAGA,WAAO,IAAI;AAAA,MACPA,aAAY;AAAA,MACZ;AAAA,QACI,GAAGA,aAAY;AAAA,QACf,SAAS;AAAA,MACb;AAAA,MACAA,aAAY;AAAA,MACZA,aAAY;AAAA,MACZ,QAAQ;AAAA,MACR,QAAQ;AAAA,MACRA,aAAY;AAAA,MACZ,QAAQ;AAAA;AAAA;AAAA;AAAA,IAIZ;AAAA,EACJ,SAAS,OAAgB;AACrB,UAAM,IAAI,mBAAmB,gDAAgD,KAAK,EAAE;AAAA,EACxF;AACJ,CAAC;AA8DM,IAAM,uBAAuB,CAChC,KACA,MAAiC,6BAA6B,MACrD;AAET,QAAM,oBAAoB,qBAAqB,GAAG;AAElD,aAAW,CAAC,aAAa,UAAU,KAAK,OAAO,QAAQ,iBAAiB,GAAG;AACvE,QAAI,eAAe,KAAK;AACpB,aAAO;AAAA,IACX;AAAA,EACJ;AAGA,SAAO,OAAO,oCAAoC,GAAG,KAAK,UAAU,GAAG,CAAC,GAAG;AAC/E;AAWO,IAAM,uBAAuB;AAAA,EAChC,CAAC,MAAiC,6BAA6B,MAA8C;AAEzG,UAAM,iBAAiB,OAAO,QAAQ,IAAI,OAAO,QAAQ;AAEzD,UAAM,aAAa,eAAe;AAAA,MAC9B,CAAC,CAAC,aAAa,aAAa,MAAM,CAAC,aAAa,cAAc,GAAG;AAAA,IACrE;AAEA,UAAM,oBAAoB,OAAO,YAAY,UAAU;AAMvD,UAAM,2BAA2B,WAAW,OAAO,CAAC,CAAC,GAAG,GAAG,MAAM,OAAO,IAAI;AAC5E,UAAM,2BAA2B,OAAO,YAAY,wBAAwB;AAG5E,UAAM,iBAAiB,IAAI,IAAI,OAAO,OAAO,wBAAwB,CAAC;AACtE,UAAM,kBAAkB,IAAI,IAAI,OAAO,KAAK,wBAAwB,CAAC;AAGrE,QAAI,eAAe,SAAS,gBAAgB,MAAM;AAC9C,aAAO;AAAA,IACX;AAUA,UAAM,yBAAyB,MAAM,KAAK,cAAc,EAEnD;AAAA,MAAI,CAAC,QACF,yBAAyB;AAAA,QAAQ,CAAC,CAAC,aAAa,UAAU,MACtD,QAAQ,aAAa,CAAC,WAAW,IAAI,CAAC;AAAA,MAC1C;AAAA,IACJ,EAEC,OAAO,CAAC,iBAAiB,aAAa,SAAS,CAAC;AAGrD,UAAM,WAAW,uBACZ;AAAA,MACG,CAAC,iBACG,KAAK,aAAa,KAAK,IAAI,CAAC,oBAAoB,UAAU,kBAAkB,aAAa,CAAC,CAAE,CAAE,CAAC;AAAA,IACvG,EACC,KAAK,IAAI;AAEd,UAAM,IAAI;AAAA,MACN;AAAA;AAAA,EAA8D,QAAQ;AAAA;AAAA;AAAA,IAC1E;AAAA,EACJ;AACJ;;;AI1PA,SAAS,SAAS,oBAAoB;AACtC,SAAS,oBAAoB;AAC7B,SAAS,cAAc;AAEvB,SAAS,2BAA2B;AACpC,SAAS,oBAAsC;AAC/C,SAAS,kBAA4B;AACrC,SAAS,aAAa,aAAa;AAKnC,IAAM,MAAiC;AAAA,EACnC,MAAM;AAAA,EACN,MAAM,MAAc,OAAe;AAC/B,WAAO,oBAAoB,KAAK;AAAA,EACpC;AAAA,EACA,WAAW;AAAA,EAAC;AAChB;AAEA,IAAM,gBAAgB,CAAC,UAAwC,OAAO,OAAe,WAAW,EAAE,SAAS,KAAK;AAOhH,IAAM,cAA4C;AAAA,EAC9C,MAAM;AAAA,EACN,MAAM,MAAc,OAAe;AAC/B,QAAI,CAAC,cAAc,KAAK,GAAG;AACvB,YAAM,IAAI,aAAa,OAAO,UAAU,wBAAwB;AAAA,QAC5D;AAAA,QACA;AAAA,QACA,MAAM;AAAA,MACV,CAAC;AAAA,IACL;AAEA,WAAO;AAAA,EACX;AAAA,EACA,WAAW;AAAA,EAAC;AAChB;AAEA,IAAM,UAAU,CAAC,UAAkC,OAAO,OAAe,KAAK,EAAE,SAAS,KAAK;AAO9F,IAAM,QAAgC;AAAA,EAClC,MAAM;AAAA,EACN,MAAM,MAAc,OAAe;AAC/B,QAAI,CAAC,QAAQ,KAAK,GAAG;AACjB,YAAM,IAAI,aAAa,OAAO,UAAU,wBAAwB;AAAA,QAC5D;AAAA,QACA;AAAA,QACA,MAAM;AAAA,MACV,CAAC;AAAA,IACL;AAEA,WAAO;AAAA,EACX;AAAA,EACA,WAAW;AAAA,EAAC;AAChB;AAOA,IAAM,WAAsC;AAAA,EACxC,MAAM;AAAA,EACN,MAAM,MAAc,OAAe;AAC/B,QAAI,CAAC,WAAW,KAAK,GAAG;AACpB,YAAM,IAAI,aAAa,OAAO,UAAU,wBAAwB;AAAA,QAC5D;AAAA,QACA;AAAA,QACA,MAAM;AAAA,MACV,CAAC;AAAA,IACL;AAEA,WAAO;AAAA,EACX;AAAA,EACA,WAAW;AAAA,EAAC;AAChB;AAQO,IAAM,KAA8B;AAAA,EACvC,MAAM;AAAA,EACN,OAAO,CAAC,SAAS,UAAU;AACvB,QAAI,OAAO,UAAU,YAAY;AAC7B,YAAM,IAAI,aAAa,OAAO,UAAU,wBAAwB;AAAA,QAC5D;AAAA,QACA,MAAM;AAAA,QACN,MAAM,GAAG;AAAA,MACb,CAAC;AAAA,IACL;AAEA,WAAO;AAAA,EACX;AAAA,EACA,WAAW;AAAA,EAAC;AAChB;AAMO,IAAM,SAA4C;AAAA,EACrD,MAAM;AAAA,EACN,OAAO,CAAC,SAAS,UAAU;AAEvB,QAAI,aAAa,KAAK,GAAG;AACrB,aAAO,EAAE,MAAM,WAAW,SAAS,MAAM;AAAA,IAC7C;AAGA,UAAM,SAAS,SAAS,OAAO,EAAE;AACjC,QAAI,CAAC,MAAM,MAAM,GAAG;AAChB,UAAI,SAAS,GAAG;AACZ,cAAM,IAAI,aAAa,OAAO,UAAU,wBAAwB;AAAA,UAC5D;AAAA,UACA,MAAM;AAAA,UACN,MAAM,OAAO;AAAA,QACjB,CAAC;AAAA,MACL;AAEA,aAAO,EAAE,MAAM,SAAS,OAAO,OAAO;AAAA,IAC1C;AAGA,WAAO,EAAE,MAAM,SAAS,MAAM,MAAM;AAAA,EACxC;AAAA,EACA,WAAW;AAAA,EAAC;AAChB;AAEO,IAAM,QAAQ,EAAE,KAAK,UAAU,IAAI,QAAQ,aAAa,OAAO,GAAG,aAAa;;;AN3HtF,SAAS,qBAAqB;;;AOjB9B,OAAOC,WAAU,sBAAsB;AACvC,OAAO;AAaA,SAAS,oBACZ,KACuD;AACvD,EAAAA,QAAO,IAAI,aAAa,2DAA2D;AACvF;AASO,SAAS,sBACZ,cACA,MAAiC,6BAA6B,GACjD;AACb,QAAM,sBAAsB,IAAI,IAAI,OAAO,KAAK,qBAAqB,GAAG,CAAC,CAAC;AAE1E,aAAW,eAAe,cAAc;AACpC,QAAI,oBAAoB,IAAI,WAAW,GAAG;AACtC;AAAA,IACJ;AAEA,UAAM,IAAI,eAAe;AAAA,MACrB,SAAS,YAAY,WAAW,gDAAgD,MAAM,KAAK,mBAAmB,EAAE,KAAK,IAAI,CAAC;AAAA,IAC9H,CAAC;AAAA,EACL;AAEA,SAAO;AACX;;;APxBA,SAAS,uBAAAC,4BAA2B;AACpC,SAAS,mBAAmB;AAC5B,SAAgB,yBAAyB;AAqCzC,IAAM,SAA+B,OACjC,EAAE,UAAU,kBAAkB,MAAM,eAAe,CAAC,GAAG,UAAAC,YAAW,QAAQ,KAAK,OAAO,QAAQ,OAAO,OAAAC,OAAM,GAC3G,QACyB;AACzB,YAAU;AAGV,wBAAsB,8CAAoB,CAAC,CAAC;AAG5C,qBAAmBD,SAAQ;AAG3B,QAAM,SAAS,aAAa;AAG5B,QAAM,gBAAgB,CAAC;AACvB,SAAO,MAAM,gBAAgB,gCAAgC,sCAAsC;AACnG,SAAO,MAAM,QAAQ,qCAAqC,sCAAsC;AAGhG,MAAI;AACA,WAAO,KAAK,+BAA+B;AAE3C,UAAM,IAAI,IAAI,YAAY;AAAA,EAC9B,SAAS,OAAO;AACZ,WAAO,KAAK,kCAAkC,KAAK,EAAE;AAAA,EACzD;AAGA,MAAI,oBAAoB,QAAQC,UAAS,MAAM;AAC3C,WAAO,MAAM,WAAWA,MAAK,kDAAkD,iBAAiB,KAAK,GAAG,CAAC,EAAE;AAE3G,YAAQ,KAAK,CAAC;AAAA,EAClB;AAGA,QAAM,iBAAiB,OAAO,QAAQ,qBAAqB,CAAC;AAE5D,QAAM,yBACFA,UAAS,OACH,iBACA,eAAe,OAAO,CAAC,CAAC,EAAE,GAAG,MAAM,OAAO,QAAQ,kBAAkB,GAAG,MAAMA,MAAK;AAC5F,QAAM,yBAAyB,uBAAuB,QAAQ,CAAC,CAAC,MAAM,GAAG,MAAO,OAAO,OAAO,CAAC,IAAI,CAAC,IAAI,CAAE;AAG1G,QAAM,WAAqB,8CAAoB;AAG/C,MAAI;AAEJ,MAAI;AAEJ,MAAI,eAAe;AAIf,UAAM,cAAc,IAAI,IAAI,QAAQ;AAEpC,UAAM,UAAkC,eACnC,IAAI,CAAC,CAAC,aAAa,GAAG,OAAO;AAAA,MAC1B,OAAO;AAAA,MACP,OAAO;AAAA,MACP,UAAU,OAAO;AAAA,MACjB,UAAU,YAAY,IAAI,WAAW;AAAA,MACrC,MAAM,OAAO,OAAO,SAAY,gBAAgBP,WAAU,GAAG,CAAC;AAAA,IAClE,EAAE,EACD;AAAA,MACG,CAAC,GAAG;AAAA;AAAA,QAEA,OAAO,EAAE,QAAQ,IAAI,OAAO,EAAE,QAAQ;AAAA,QAEtC,EAAE,MAAM,cAAc,EAAE,KAAK;AAAA;AAAA,IACrC;AAGJ,uBAAmB,MAAM,uBAAuB,4CAA4C,EAAE,QAAQ,CAAC;AAGvG,mBAAe,MAAM,cAAc,mDAAmD;AAAA,MAClF,cAAc,6CAAc,KAAK;AAAA,MACjC,MAAM;AAAA,IACV,CAAC,EAAE,KAAKK,oBAAmB;AAAA,EAC/B,OAAO;AAEH,uBAAmB;AACnB,mBAAe;AAAA,EACnB;AAGA,MAAI,iBAAiB,WAAW,GAAG;AAC/B,WAAO,OAAO,KAAK,+BAA+B,GAAG,CAAC;AAAA,EAC1D;AAGA,SAAO;AAAA,IACH;AAAA,MACI,iBAAiB;AAAA,MACjB,0BAA0B,iBAAiB,KAAK,GAAG,CAAC;AAAA,MACpD,eAAe,iBAAiB,MAAM,cAAc,iBAAiB,KAAK,IAAI,CAAC;AAAA,IACnF;AAAA,EACJ;AAEA,MAAI,aAAa,WAAW,GAAG;AAE3B,WAAO,KAAK,iCAAiC;AAAA,EACjD,OAAO;AACH,WAAO,KAAK,uCAAuC,aAAa,KAAK,IAAI,CAAC,EAAE;AAAA,EAChF;AAGA,QAAM,eAAe,gBAAgB,MAAM,iBAAiB,IAAI;AAChE,MAAI,CAAC,cAAc;AACf,WAAO,OAAO,QAAQ,uCAAuC,GAAG,CAAC;AAAA,EACrE;AAGA,SAAO,QAAQ,4BAA4B;AAG3C,QAAM,cAAc,OAAO,kBAAkB,EAAE,QAAQ,iBAAiB,OAAO,MAAM,iBAAiB,MAAM,GAAG,CAAC,CAAC;AAKjH,MAAI,eAAuB;AAG3B,QAAM,UAAyB,CAAC;AAGhC,QAAM,QAAQ;AAAA,IACV,iBAAiB,IAAI,OAAO,gBAAgB;AAExC,YAAM,MAAM,MAAM,oBAAoB,WAAW;AAEjD,UAAI;AAEA,4BAAoB,GAAG;AAUvB,cAAM,oBAAoB,MAAM,IAAI,YAAY,IAAI;AAGpD,cAAM,mBAAmB,MAAM,IAAI,YAAY,IAAI,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAM7D,aAAa;AAAA,UACb,yBAAyB;AAAA,UACzB,2BAA2B;AAAA,QAC/B,CAAC;AAGD,cAAM,YAAY,OAAO;AAAA,UACrB,OAAO,QAAQ,gBAAgB,EAAE;AAAA,YAC7B,CAAC,CAAC,IAAI,MAAM,CAAC,YAAY,kBAAkB,IAAI,GAAG,iBAAiB,IAAI,CAAC;AAAA,UAC5E;AAAA,QACJ;AAEA,gBAAQ,WAAW,IAAI,EAAE,UAAU;AAEnC,eAAO,MAAM,iCAAiC,WAAW,EAAE;AAAA,MAC/D,SAAS,OAAgB;AAKrB,gBAAQ,WAAW,IAAI,EAAE,MAAM;AAE/B,eAAO,MAAM,4BAA4B,WAAW,KAAK,KAAK,EAAE;AAAA,MACpE,UAAE;AACE;AAGA,oBAAY;AAAA,UACR,kBAAkB;AAAA,YACd,QAAQ;AAAA,YACR,OAAO,IAAI,YAAY,IAAI,iBAAiB,MAAM;AAAA,YAClD,UAAU;AAAA,UACd,CAAC;AAAA,QACL;AAAA,MACJ;AAAA,IACJ,CAAC;AAAA,EACL;AAGA,cAAY,MAAM;AAGlB,QAAM,SAAS,OAAO,QAAQ,OAAO,EAAE;AAAA,IAAQ,CAAC,CAAC,aAAa,EAAE,MAAM,CAAC,MACnE,SAAS,OAAO,CAAC,IAAI,CAAC,EAAE,aAAa,MAAM,CAAC;AAAA,EAChD;AAGA,MAAI,OAAO,WAAW,GAAG;AACrB,WAAO,OAAO,KAAK,GAAG,aAAa,IAAI,CAAC,kCAAkC,GAAG;AAAA,EACjF;AAGA,SAAO;AAAA,IACH,GAAG,aAAa,KAAK,CAAC,IAAI,cAAc,OAAO,QAAQ,8BAA8B,oBAAoB,OAAO,MAAM,WAAW,CAAC;AAAA,EACtI;AAGA,QAAM,gBAAgB,gBAAgB,MAAM,iBAAiB,8CAA8C,IAAI;AAC/G,MAAI,eAAe;AACf;AAAA,MACI,OAAO,IAAI,CAAC,EAAE,aAAa,MAAM,OAAO;AAAA,QACpC,SAAS;AAAA,QACT,OAAO,OAAO,KAAK;AAAA,MACvB,EAAE;AAAA,IACN;AAAA,EACJ;AAGA,UAAQ,WAAW,QAAQ,YAAY;AAEvC,SAAO;AACX;AAEAN,MAAK,gBAAgB,8BAA8B,MAAM,EACpD;AAAA,EACG;AAAA,EACA;AAAA,EACA;AAAA,EACA,MAAM;AAAA,EACN;AACJ,EACC;AAAA,EACG;AAAA,EACA;AAAA,EACA;AAAA,EACA,MAAM;AAAA,EACN;AACJ,EACC,SAAS,YAAY,mEAAmE,QAAQ,MAAM,QAAQ,EAC9G,SAAS,SAAS,kDAAkD,QAAW,MAAM,OAAO,IAAI,EAChG,QAAQ,MAAM,yFAAyF,EACvG,QAAQ,SAAS,6BAA6B;;;AQpTnD,OAAO;;;ACIP,SAAS,QAAAA,aAAY;AACrB,SAAS,aAAAS,kBAAiB;AAC1B,SAAmB,gBAAAC,eAAc,QAAQ,WAAW,sBAAAC,2BAA0B;;;ACJ9E,SAAS,eAAe;AAExB,SAAS,YAAY;AACrB,YAAY,OAAO;AASZ,IAAM,0BAA0B,CACnC,YACA,kBACgB;AAjBpB;AAiBwB;AAAA,IACpB,OAAM,gBAAW,SAAX,YAAmB;AAAA,IACzB,WAAW,QAAQ,cAAc,MAAM,OAAM,gBAAW,cAAX,YAAwB,YAAY;AAAA,IACjF,OAAO;AAAA;AAAA,MAEH,UAAU;AAAA,MACV,GAAG,WAAW;AAAA;AAAA;AAAA,MAGd,MAAM;AAAA,MACN,MAAM;AAAA,IACV;AAAA,EACJ;AAAA;AAgBO,IAAM,qCAAqC,CAC9C,QACA,mBAEA;AAAA,EACI;AAAA;AAAA,EAEE,SAAO,mBAAmB;AAAA;AAAA,EAE1B;AAAA,IACE,CAAC,mBAAoD;AAAA,MACjD,GAAG,OAAO;AAAA,MACV,SAAS,cAAc;AAAA,IAC3B;AAAA,EACJ;AACJ;AA6DG,IAAM,qBAAqB,CAAC,aAC7B,kBAAuC,CAAC,gBAAwB,SAAS,SAAS,WAAW,CAAC;AAQpG,IAAM,sBAAsB,CAAC,kBACzB,SAAS,iBAAiB,OAAO,cAAc,QAAQ;;;AD1H3D,SAAS,YAAY;AACrB,SAAS,iBAAiB;AAM1B,IAAMC,UAA6C,OAAO,EAAE,UAAAL,YAAW,OAAO,GAAG,QAAQ;AAhBzF;AAiBI,EAAAI,oBAAmBJ,SAAQ;AAE3B,EAAAE,WAAU;AAEV,QAAM,SAASC,cAAa;AAG5B,QAAM,wBAAuB,qBAAI,WAAW,cAAf,mBAA0B,iBAA1B,mBAAwC,eAAxC,YAAsD,CAAC;AACpF,SAAO,QAAQ;AAAA,EAAkC,UAAU,oBAAoB,CAAC,EAAE;AAGlF,QAAM,mBAAmB,wBAAwB,sBAAsB,IAAI,MAAM;AACjF,SAAO,QAAQ;AAAA,EAAgC,UAAU,gBAAgB,CAAC,EAAE;AAG5E,QAAM,oBAAoB,KAAK,iBAAiB,WAAW,qBAAqB;AAChF,MAAI,CAAC,OAAO,iBAAiB,GAAG;AAC5B,WAAO,KAAK,kDAAkD,iBAAiB,GAAG;AAClF,WAAO,KAAK,4BAA4B,6BAA6B,IAAI;AAEzE,YAAQ,WAAW;AAEnB;AAAA,EACJ;AAMA,MAAI;AACA,WAAO,QAAQ,4CAA4C,iBAAiB,EAAE;AAE9E,cAAU,UAAU,CAAC,WAAW,MAAM,mBAAmB,MAAM,GAAG;AAAA,MAC9D,OAAO;AAAA,IACX,CAAC;AAAA,EACL,SAAS,OAAO;AACZ,WAAO,MAAM,mDAAmD,iBAAiB,KAAK,KAAK,EAAE;AAE7F,YAAQ,WAAW;AAEnB;AAAA,EACJ;AACJ;AAEA,IAAI,QAAQ,IAAI,mCAAmC;AAC/C,EAAAV,MAAK,8BAA8B,gDAAgDY,OAAM,EAAE;AAAA,IACvF;AAAA,IACA;AAAA,IACA;AAAA,IACA,MAAM;AAAA,EACV;AACJ;;;AEhEA,SAAS,QAAAZ,aAAY;AAErB,SAAS,aAAAS,kBAAiB;AAC1B,SAAmB,gBAAAC,eAAc,aAAAG,YAAW,sBAAAF,2BAA0B;AACtE,SAAS,WAAW,qBAAqB;AACzC,SAAS,QAAAG,aAAY;AACrB,SAAS,kCAAkC;;;ACV3C,SAAS,QAAAC,aAAY;AACrB,YAAY,QAAQ;AAEpB,SAA4B,6BAA6B;AAUlD,IAAM,2BAA2B,CAAC,kBAAoD;AAAA;AAAA;AAAA;AAAA;AAAA,EAKzF,OAAO;AAAA,IACH,YAAY;AAAA,IACZ,QAAQ;AAAA,EACZ;AAAA,EACA,SAAS,CAAC,SAAS,GAAG,sBAAsB,YAAY,CAAC;AAC7D;AAUO,IAAM,gCAAgC,CACzC,MACA,qBACsB;AAAA;AAAA;AAAA;AAAA;AAAA,EAKtB,OAAO;AAAA,IACH,YAAY;AAAA,IACZ,QAAQ;AAAA,EACZ;AAAA;AAAA;AAAA;AAAA;AAAA,EAKA,OAAO,CAAC,GAAG,IAAI,OAAO;AAAA,EACtB,YAAYA;AAAA,IACR;AAAA;AAAA;AAAA;AAAA,IAIG,OAAI,OAAO;AAAA,MACV,WAAW;AAAA,IACf,EAAE;AAAA,EACN;AACJ;AAUO,IAAM,8BAA8B,CACvC,QACA,cACe;AAAA,EACf,SAAS;AAAA,EACT,UAAUA;AAAA,IACN;AAAA;AAAA,IAEG,OAAI,wBAAwB;AAAA,IAC/B,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASGA;AAAA,QACI;AAAA,QACG,YAAS,OAAO,8BAA8B,OAAO,MAAM,mBAAmB,CAAC;AAAA,MACtF;AAAA;AAAA,EACR;AACJ;;;AC5FA;;;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;AHgBA,SAAS,aAAAC,kBAAiB;AAQ1B,IAAMJ,UAA8C,OAChD,EAAE,UAAU,kBAAkB,SAAS,OAAO,UAAAL,YAAW,OAAO,GAChE,QACC;AA3BL;AA4BI,EAAAI,oBAAmBJ,SAAQ;AAE3B,EAAAE,WAAU;AAEV,QAAM,SAASC,cAAa;AAG5B,QAAM,WAAW;AAAA;AAAA,IAEX,sBAAsB,gBAAgB;AAAA;AAAA;AAAA,IAEtC,OAAO,QAAQ,qBAAqB,GAAG,CAAC,EAAE,QAAQ,CAAC,CAAC,aAAa,GAAG,MAAO,OAAO,OAAO,CAAC,IAAI,CAAC,WAAW,CAAE;AAAA;AAMlH,MAAI,SAAS,WAAW,GAAG;AACvB,WAAO,KAAK,0CAA0C;AAEtD;AAAA,EACJ;AAEA,SAAO,KAAK,uDAAuD,SAAS,KAAK,IAAI,CAAC,EAAE;AAGxF,QAAM,wBAAuB,qBAAI,WAAW,cAAf,mBAA0B,iBAA1B,mBAAwC,eAAxC,YAAsD,CAAC;AACpF,SAAO,QAAQ;AAAA,EAAkCG,WAAU,oBAAoB,CAAC,EAAE;AAGlF,QAAM,mBAAmB,wBAAwB,sBAAsB,IAAI,MAAM;AACjF,SAAO,QAAQ;AAAA,EAAgCA,WAAU,gBAAgB,CAAC,EAAE;AAG5E,QAAM,iBAAiB,mBAAmB,QAAQ,EAAE,IAAI,OAAO,QAAQ;AAGvE,QAAM,eAAe,mCAAmC,kBAAkB,cAAc;AACxF,SAAO,QAAQ;AAAA,EAAyBA,WAAU,YAAY,CAAC,EAAE;AAGjE,QAAM,cAAc,4BAA4B,kBAAkB,YAAY;AAC9E,QAAM,wBAAwB,2BAA2B,WAAW;AAGpE,SAAO,QAAQ,yBAAyB,iBAAiB,SAAS,SAAS;AAC3E,YAAU,iBAAiB,WAAW,EAAE,WAAW,KAAK,CAAC;AAEzD,QAAM,iBAAiBC,MAAK,iBAAiB,WAAW,YAAY;AACpE,SAAO,MAAM,oCAAoC,cAAc,EAAE;AACjE,gBAAc,gBAAgB,kBAAU;AAExC,QAAM,gBAAgBA,MAAK,iBAAiB,WAAW,YAAY;AACnE,SAAO,MAAM,kDAAkD,aAAa,EAAE;AAC9E,gBAAc,eAAe,aAAS;AAEtC,QAAM,oBAAoBA,MAAK,iBAAiB,WAAW,qBAAqB;AAChF,SAAO,MAAM,kDAAkD,iBAAiB,EAAE;AAClF,gBAAc,mBAAmB,qBAAqB;AAMtD,MAAI;AACA,QAAI,QAAQ;AACR,aAAO,KAAK,uCAAuC;AACnD,aAAO;AAAA,QACH,wDAAwD,4BAA4B;AAAA,MACxF;AAAA,IACJ,OAAO;AACH,aAAO,KAAK,qBAAqB;AAAA,IACrC;AAEA,WAAO,QAAQ,0CAA0C,iBAAiB,EAAE;AAG5E,UAAM,mBAA6B,SAAS,CAAC,QAAQ,IAAI,CAAC;AAE1D,IAAAE,WAAU,UAAU,CAAC,WAAW,MAAM,mBAAmB,MAAM,GAAG,gBAAgB,GAAG;AAAA,MACjF,OAAO;AAAA,IACX,CAAC;AAAA,EACL,SAAS,OAAO;AACZ,WAAO,MAAM,iDAAiD,iBAAiB,KAAK,KAAK,EAAE;AAE3F,YAAQ,WAAW;AAEnB;AAAA,EACJ;AACJ;AAEA,IAAI,QAAQ,IAAI,mCAAmC;AAC/C,EAAAhB,MAAK,+BAA+B,yCAAyCY,OAAM,EAC9E,SAAS,YAAY,mEAAmE,QAAQ,MAAM,QAAQ,EAC9G,SAAS,YAAY,gDAAgD,QAAW,MAAM,KAAK,IAAI,EAC/F,QAAQ,UAAU,wCAAwC;AACnE;;;AIxHA,SAAS,QAAAZ,aAAY;AACrB,SAAS,aAAAS,kBAAiB;AAC1B,SAAmB,gBAAAC,eAAc,UAAAO,SAAQ,aAAAJ,YAAW,sBAAAF,2BAA0B;AAG9E,SAAS,QAAAG,aAAY;AACrB,SAAS,aAAAE,kBAAiB;AAC1B,SAAS,cAAc;AAMvB,IAAMJ,UAA6C,OAAO,EAAE,UAAAL,YAAW,OAAO,GAAG,QAAQ;AAjBzF;AAkBI,EAAAI,oBAAmBJ,SAAQ;AAE3B,EAAAE,WAAU;AAEV,QAAM,SAASC,cAAa;AAG5B,QAAM,wBAAuB,qBAAI,WAAW,cAAf,mBAA0B,iBAA1B,mBAAwC,eAAxC,YAAsD,CAAC;AACpF,SAAO,QAAQ;AAAA,EAAkCG,WAAU,oBAAoB,CAAC,EAAE;AAGlF,QAAM,mBAAmB,wBAAwB,sBAAsB,IAAI,MAAM;AACjF,SAAO,QAAQ;AAAA,EAAgCA,WAAU,gBAAgB,CAAC,EAAE;AAG5E,QAAM,oBAAoBC,MAAK,iBAAiB,WAAW,qBAAqB;AAChF,MAAI,CAACG,QAAO,iBAAiB,GAAG;AAC5B,WAAO,KAAK,kDAAkD,iBAAiB,GAAG;AAClF,WAAO,KAAK,4BAA4B,6BAA6B,IAAI;AAEzE,YAAQ,WAAW;AAEnB;AAAA,EACJ;AAMA,MAAI;AACA,WAAO,KAAK,qBAAqB;AACjC,WAAO,QAAQ,4CAA4C,iBAAiB,EAAE;AAE9E,IAAAD,WAAU,UAAU,CAAC,WAAW,MAAM,mBAAmB,MAAM,GAAG;AAAA,MAC9D,OAAO;AAAA,IACX,CAAC;AAAA,EACL,SAAS,OAAO;AACZ,WAAO,MAAM,mDAAmD,iBAAiB,KAAK,KAAK,EAAE;AAE7F,YAAQ,WAAW;AAEnB;AAAA,EACJ,UAAE;AACE,QAAI;AACA,aAAO,iBAAiB,WAAW,EAAE,OAAO,MAAM,WAAW,KAAK,CAAC;AAAA,IACvE,SAAS,OAAO;AACZ,aAAO,MAAM,qBAAqB,iBAAiB,SAAS,MAAM,KAAK,EAAE;AAAA,IAC7E;AAAA,EACJ;AACJ;AAEA,IAAI,QAAQ,IAAI,mCAAmC;AAC/C,EAAAhB,MAAK,8BAA8B,uCAAuCY,OAAM,EAAE;AAAA,IAC9E;AAAA,IACA;AAAA,IACA;AAAA,IACA,MAAM;AAAA,EACV;AACJ;;;AC5EA,SAAS,yBAAyB,iCAAuD;AAGlF,IAAM,wBAAwB,CACjC,iBACwD;AAAA,EACxD,SAAS,qBAAqB,YAAY,MAAM,GAAG;AAAA,EACnD,GAAG,0BAA0B,WAAW;AAC5C;;;ACLA;AAAA,EAMI;AAAA,OACG;AACP;AAAA,EACI,gBAAAF;AAAA,EACA;AAAA,EACA,iBAAAQ;AAAA,EACA,gBAAAC;AAAA,EACA,aAAAN;AAAA,EACA,oBAAAO;AAAA,OACG;AACP,SAAS,qBAAAC,oBAAmB,gBAAAC,eAAc,UAAAC,eAAc;AACxD,SAAS,WAAAC,gBAAe;AASxB,IAAMZ,UAA0C,OAAO;AAAA,EACnD;AAAA,EACA;AAAA,EACA;AACJ,MAAkC;AAE9B,QAAM,gBAAgB,CAAC;AAEvB,QAAM,SAASF,cAAa;AAC5B,QAAM,gBAAgB,mBAAmB,wBAAwB;AAGjE,QAAM,sBAAsB,gBACtB,MAAMU,kBAAiB,+DAA+D,IACtF;AACN,MAAI,qBAAqB;AACrB,IAAAE,cAAa,aAAa,IAAI,qBAAqB,CAAC;AAAA,EACxD;AAKA,QAAM,eAAe,gBACf,MAAMF,kBAAiB,qDAAqD,IAC5E;AACN,MAAI,CAAC,cAAc;AACf,WAAO,cAAc,QAAQ,uCAAuC,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,YAAY;AAAA,EAChG;AAEA,gBAAc,QAAQ;AAAA;AAAA,EAAwCP,WAAU,YAAY,CAAC,EAAE;AAKvF,QAAM,cAAc,kBAAkB,YAAY;AAGlD,MAAI,qBAAwC;AAC5C,MAAI,yBAAuD,CAAC;AAC5D,MAAI,SAAqC,CAAC;AAW1C,SAAO,MAAM;AAET,UAAM,cAAcU;AAAA,MAChBF,mBAAkB,EAAE,QAAQ,eAAe,OAAO,MAAM,mBAAmB,MAAM,GAAG,CAAC;AAAA,IACzF;AAEA,kBAAc,QAAQ,0BAA0B;AAChD,UAAM,CAAC,iBAAiB,aAAa,YAAY,IAAI,MAAM;AAAA,MACvD;AAAA,MACA,CAAC,QAAQ,YAAY;AAEjB,oBAAY;AAAA,UACRA,mBAAkB;AAAA,YACd,UAAU,QAAQ,SAAS,mBAAmB;AAAA,YAC9C,QAAQ;AAAA,YACR,OAAO,IAAI,QAAQ,MAAM,IAAI,mBAAmB,MAAM;AAAA,UAC1D,CAAC;AAAA,QACL;AAAA,MACJ;AAAA,IACJ;AAGA,gBAAY,MAAM;AAKlB,6BAAyB,CAAC,GAAG,wBAAwB,GAAG,eAAe;AAIvE,aAAS;AAET,yBAAqB;AAErB,kBAAc,QAAQ,uBAAuB;AAC7C,kBAAc,MAAM;AAAA;AAAA,EAAoDR,WAAU,eAAe,CAAC,EAAE;AACpG,kBAAc,MAAM;AAAA;AAAA,EAAiDA,WAAU,WAAW,CAAC,EAAE;AAC7F,kBAAc,MAAM;AAAA;AAAA,EAA+CA,WAAU,YAAY,CAAC,EAAE;AAG5F,WAAO;AAAA,MACHK;AAAA,QACI,gBAAgB;AAAA,QAChB;AAAA,QACA,qBAAqB,gBAAgB,MAAM;AAAA,MAC/C;AAAA,IACJ;AAGA,QAAI,OAAO,WAAW,GAAG;AACrB,aAAO,KAAK,GAAGC,cAAa,IAAI,CAAC,8BAA8B;AAE/D;AAAA,IACJ;AAGA,WAAO;AAAA,MACHD,eAAc,OAAO,QAAQ,gCAAgC,kBAAkB,OAAO,MAAM,eAAe;AAAA,IAC/G;AAEA,UAAM,gBAAgB,gBAChB,MAAME,kBAAiB,oDAAoD,IAC3E;AACN,QAAI,eAAe;AACf,MAAAE;AAAA,QACI,OAAO,IAAI,CAAC,EAAE,OAAO,YAAY,OAAO;AAAA,UACpC,OAAO,OAAO,KAAK;AAAA,UACnB,GAAG,sBAAsB,WAAW;AAAA,QACxC,EAAE;AAAA,MACN;AAAA,IACJ;AAKA,UAAM,QAAQ,gBAAgB,MAAMF,kBAAiB,4BAA4B,IAAI,IAAI;AACzF,QAAI,CAAC,OAAO;AACR,aAAO,MAAM,GAAGD,cAAa,KAAK,CAAC,+BAA+B;AAElE;AAAA,IACJ;AAAA,EACJ;AAEA,SAAO,CAAC,wBAAwB,QAAQ,kBAAkB;AAC9D;AAEAK,SAAQ,0BAA0B,6DAA6DZ,OAAM,EAChG,QAAQ,MAAM,yFAAyF,EACvG,SAAS,gBAAgB,mCAAmC,QAAW,MAAM,GAAG,EAChF,SAAS,gBAAgB,2DAA2D,QAAW,MAAM,EAAE;;;ACzK5G,SAAS,QAAAZ,aAAY;AAGrB,SAAqB,qBAAqB,UAAU,2BAA2B;AAC/E,SAAS,gBAAAU,eAAc,iBAAAQ,gBAAe,gBAAAC,eAAc,sBAAAR,2BAA0B;AAE9E,SAAS,aAAAF,kBAAiB;AAU1B,IAAMG,UAA+B,OACjC,EAAE,UAAU,WAAW,UAAAL,YAAW,QAAQ,SAAS,YAAY,GAC/D,QACwB;AACxB,EAAAE,WAAU;AAGV,EAAAE,oBAAmBJ,SAAQ;AAG3B,QAAM,SAASG,cAAa;AAG5B,QAAM,UAAU,SAAS;AAAA;AAAA,IAErB,gBAAgB,IAAI,OAAO,MAAM;AAAA,IACjC;AAAA,IACA,uBAAuB,oBAAoB,SAAS;AAAA,IACpD,mBAAmB,oBAAoB,QAAQ;AAAA,IAC/C,WAAW;AAAA,EACf,CAAC;AAED,SAAO;AAAA,IACH,GAAGS,cAAa,IAAI,CAAC,IAAID,eAAc,QAAQ,QAAQ,qBAAqB,aAAa,QAAQ,MAAM,QAAQ,CAAC;AAAA,EACpH;AAEA,aAAW,EAAE,KAAK,KAAK,SAAS;AAC5B,WAAO,KAAK,IAAK,IAAI,EAAE;AAAA,EAC3B;AAEA,SAAO;AACX;AAEAlB,MAAK,uCAAuC,0CAA0CY,OAAM,EACvF;AAAA,EACG;AAAA,EACA;AAAA,EACA;AAAA,EACA,MAAM;AAAA,EACN;AACJ,EACC;AAAA,EACG;AAAA,EACA;AAAA,EACA;AAAA,EACA,MAAM;AAAA,EACN;AACJ,EACC,SAAS,YAAY,mEAAmE,QAAQ,MAAM,QAAQ","sourcesContent":["import { task } from 'hardhat/config'\nimport type { ActionType } from 'hardhat/types'\nimport { TASK_COMPILE } from 'hardhat/builtin-tasks/task-names'\nimport { TASK_LZ_DEPLOY } from '@/constants/tasks'\nimport {\n    PromptOption,\n    createLogger,\n    pluralizeNoun,\n    printBoolean,\n    promptToContinue,\n    promptToSelectMultiple,\n    setDefaultLogLevel,\n} from '@layerzerolabs/io-devtools'\n\nimport { createProgressBar, printLogo, printRecords, render } from '@layerzerolabs/io-devtools/swag'\nimport { formatEid } from '@layerzerolabs/devtools'\nimport { getEidsByNetworkName, getHreByNetworkName } from '@/runtime'\nimport { types } from '@/cli'\nimport { promptForText } from '@layerzerolabs/io-devtools'\nimport { Deployment } from 'hardhat-deploy/dist/types'\nimport { assertDefinedNetworks, assertHardhatDeploy } from '@/internal/assertions'\nimport { splitCommaSeparated } from '@layerzerolabs/devtools'\nimport { isDeepEqual } from '@layerzerolabs/devtools'\nimport { Stage, endpointIdToStage } from '@layerzerolabs/lz-definitions'\n\ninterface TaskArgs {\n    networks?: string[]\n    stage?: Stage\n    tags?: string[]\n    logLevel?: string\n    ci?: boolean\n    reset?: boolean\n}\n\n/**\n * Result of this task, a map of `NetworkDeployResult` objects keyed by network names\n *\n * @see {@link NetworkDeployResult}\n */\ntype DeployResults = Record<string, NetworkDeployResult>\n\n/**\n * Result of a deployment for one particular network.\n *\n * Unfortunately, when deployment fails partially,\n * there is now way of getting the partial deployment result from hardhat-deploy\n * and just an error is returned instead\n */\ntype NetworkDeployResult =\n    // A successful result will contain a map of deployments by their contract names\n    | {\n          contracts: Record<string, Deployment>\n          error?: never\n      }\n    // A failed result will only contain an error\n    | {\n          contracts?: never\n          error: unknown\n      }\n\nconst action: ActionType<TaskArgs> = async (\n    { networks: networksArgument, tags: tagsArgument = [], logLevel = 'info', ci = false, reset = false, stage },\n    hre\n): Promise<DeployResults> => {\n    printLogo()\n\n    // Make sure to check that the networks are defined\n    assertDefinedNetworks(networksArgument ?? [])\n\n    // We'll set the global logging level to get as much info as needed\n    setDefaultLogLevel(logLevel)\n\n    // And we'll create a logger for ourselves\n    const logger = createLogger()\n\n    // We only want to be asking users for input if we are not in interactive mode\n    const isInteractive = !ci\n    logger.debug(isInteractive ? 'Running in interactive mode' : 'Running in non-interactive (CI) mode')\n    logger.debug(reset ? 'Will delete existing deployments' : 'Will not delete existing deployments')\n\n    // The first thing to do is to ensure that the project is compiled\n    try {\n        logger.info(`Compiling you hardhat project`)\n\n        await hre.run(TASK_COMPILE)\n    } catch (error) {\n        logger.warn(`Failed to compile the project: ${error}`)\n    }\n\n    // --stage cannot be used in conjunction with --networks\n    if (networksArgument != null && stage != null) {\n        logger.error(`--stage ${stage} cannot be used in conjunction with --networks ${networksArgument.join(',')}`)\n\n        process.exit(1)\n    }\n\n    // We grab a mapping between network names and endpoint IDs\n    const eidsByNetworks = Object.entries(getEidsByNetworkName())\n    // If a stage argument is passed, we'll filter out the networks for that stage\n    const filteredEidsByNetworks =\n        stage == null\n            ? eidsByNetworks\n            : eidsByNetworks.filter(([, eid]) => eid != null && endpointIdToStage(eid) === stage)\n    const configuredNetworkNames = filteredEidsByNetworks.flatMap(([name, eid]) => (eid == null ? [] : [name]))\n\n    // We'll use all the configured network names as the default for the networks argument\n    const networks: string[] = networksArgument ?? configuredNetworkNames\n\n    // Here we'll store the final value for the networks we'd like to deploy\n    let selectedNetworks: string[]\n\n    let selectedTags: string[]\n\n    if (isInteractive) {\n        // In the interactive mode, we'll ask the user to confirm which networks they want to deploy\n\n        // We'll preselect the networks passed as --networks argument and we'll do it in O(1)\n        const networksSet = new Set(networks)\n\n        const options: PromptOption<string>[] = eidsByNetworks\n            .map(([networkName, eid]) => ({\n                title: networkName,\n                value: networkName,\n                disabled: eid == null,\n                selected: networksSet.has(networkName),\n                hint: eid == null ? undefined : `Connected to ${formatEid(eid)}`,\n            }))\n            .sort(\n                (a, b) =>\n                    // We want to show the enabled networks first\n                    Number(a.disabled) - Number(b.disabled) ||\n                    //  And sort the rest by their name\n                    a.title.localeCompare(b.title)\n            )\n\n        // Now we ask the user to confirm the network selection\n        selectedNetworks = await promptToSelectMultiple('Which networks would you like to deploy?', { options })\n\n        // And we ask to confirm the tags to deploy\n        selectedTags = await promptForText('Which deploy script tags would you like to use?', {\n            defaultValue: tagsArgument?.join(','),\n            hint: 'Leave empty to use all deploy scripts',\n        }).then(splitCommaSeparated)\n    } else {\n        // In the non-interactive mode we'll use whatever we got on the CLI\n        selectedNetworks = networks\n        selectedTags = tagsArgument\n    }\n\n    // If no networks have been selected, we exit\n    if (selectedNetworks.length === 0) {\n        return logger.warn(`No networks selected, exiting`), {}\n    }\n\n    // We'll tell the user what's about to happen\n    logger.info(\n        pluralizeNoun(\n            selectedNetworks.length,\n            `Will deploy 1 network: ${selectedNetworks.join(',')}`,\n            `Will deploy ${selectedNetworks.length} networks: ${selectedNetworks.join(', ')}`\n        )\n    )\n\n    if (selectedTags.length === 0) {\n        // Deploying all tags might not be what the user wants so we'll warn them about it\n        logger.warn(`Will use all deployment scripts`)\n    } else {\n        logger.info(`Will use deploy scripts tagged with ${selectedTags.join(', ')}`)\n    }\n\n    // Now we confirm with the user that they want to continue\n    const shouldDeploy = isInteractive ? await promptToContinue() : true\n    if (!shouldDeploy) {\n        return logger.verbose(`User cancelled the operation, exiting`), {}\n    }\n\n    // We talk we talk we talk\n    logger.verbose(`Running deployment scripts`)\n\n    // Now we render a progressbar to monitor the deployment progress\n    const progressBar = render(createProgressBar({ before: 'Deploying... ', after: ` 0/${selectedNetworks.length}` }))\n\n    // For now we'll use a very simple deployment logic with no retries\n    //\n    // For display purposes, we'll track the number of networks we deployed\n    let numProcessed: number = 0\n\n    // And for diplay purposes we'll also track the failures\n    const results: DeployResults = {}\n\n    // Now we run all the deployments\n    await Promise.all(\n        selectedNetworks.map(async (networkName) => {\n            // First we grab the hre for that network\n            const env = await getHreByNetworkName(networkName)\n\n            try {\n                // We need to make sure the user has enabled hardhat-deploy\n                assertHardhatDeploy(env)\n\n                // We first collect all existing deployments\n                //\n                // We do this so that we can diff the state before and after\n                // running the deployment scripts.\n                //\n                // This is, in immediate effect, a workaround for having to set resetMemory\n                // in the options for the run() function below to false. In near future though\n                // it opens doors for being able to return partially successful deployment results\n                const deploymentsBefore = await env.deployments.all()\n\n                // The core of this task, running the hardhat deploy scripts\n                const deploymentsAfter = await env.deployments.run(selectedTags, {\n                    // If we don't pass resetmemory or set it to true,\n                    // hardhat deploy will erase the database of deployments\n                    // (including the external deployments)\n                    //\n                    // In effect this means the deployments for LayerZero artifacts would not be available\n                    resetMemory: false,\n                    writeDeploymentsToFiles: true,\n                    deletePreviousDeployments: reset,\n                })\n\n                // Now we do a little diff on what contracts had been changed\n                const contracts = Object.fromEntries(\n                    Object.entries(deploymentsAfter).filter(\n                        ([name]) => !isDeepEqual(deploymentsBefore[name], deploymentsAfter[name])\n                    )\n                )\n\n                results[networkName] = { contracts }\n\n                logger.debug(`Successfully deployed network ${networkName}`)\n            } catch (error: unknown) {\n                // If we fail to deploy, we just store the error and continue\n                //\n                // Unfortunately, there is no way of knowing whether the failure was total\n                // or partial so we don't know whether there are any contracts that got deployed\n                results[networkName] = { error }\n\n                logger.debug(`Failed deploying network ${networkName}: ${error}`)\n            } finally {\n                numProcessed++\n\n                // Now we update the progressbar\n                progressBar.rerender(\n                    createProgressBar({\n                        before: 'Deploying... ',\n                        after: ` ${numProcessed}/${selectedNetworks.length}`,\n                        progress: numProcessed,\n                    })\n                )\n            }\n        })\n    )\n\n    // We drop the progressbar and continue\n    progressBar.clear()\n\n    // We check whether we got any errors\n    const errors = Object.entries(results).flatMap(([networkName, { error }]) =>\n        error == null ? [] : [{ networkName, error }]\n    )\n\n    // If nothing went wrong we just exit\n    if (errors.length === 0) {\n        return logger.info(`${printBoolean(true)} Your contracts are now deployed`), results\n    }\n\n    // We log the fact that there were some errors\n    logger.error(\n        `${printBoolean(false)} ${pluralizeNoun(errors.length, 'Failed to deploy 1 network', `Failed to deploy ${errors.length} networks`)}`\n    )\n\n    // If some of the deployments failed, we let the user know\n    const previewErrors = isInteractive ? await promptToContinue(`Would you like to see the deployment errors?`) : true\n    if (previewErrors) {\n        printRecords(\n            errors.map(({ networkName, error }) => ({\n                Network: networkName,\n                Error: String(error),\n            }))\n        )\n    }\n\n    // Mark the process as unsuccessful (only if it has not yet been marked as such)\n    process.exitCode = process.exitCode || 1\n\n    return results\n}\n\ntask(TASK_LZ_DEPLOY, 'Deploy LayerZero contracts', action)\n    .addParam(\n        'networks',\n        'List of comma-separated networks. If not provided, all networks will be deployed',\n        undefined,\n        types.csv,\n        true\n    )\n    .addParam(\n        'tags',\n        'List of comma-separated deploy script tags to deploy. If not provided, all deploy scripts will be executed',\n        undefined,\n        types.csv,\n        true\n    )\n    .addParam('logLevel', 'Logging level. One of: error, warn, info, verbose, debug, silly', 'info', types.logLevel)\n    .addParam('stage', 'Chain stage. One of: mainnet, testnet, sandbox', undefined, types.stage, true)\n    .addFlag('ci', 'Continuous integration (non-interactive) mode. Will not ask for any input from the user')\n    .addFlag('reset', 'Delete existing deployments')\n","export const TASK_LZ_DEPLOY = 'lz:deploy'\n\nexport const TASK_LZ_EXPORT_DEPLOYMENTS_TYPESCRIPT = 'lz:export:deployments:typescript'\n\nexport const SUBTASK_LZ_SIGN_AND_SEND = '::lz:sign-and-send'\n\nexport const TASK_LZ_TEST_SIMULATION_START = 'lz:test:simulation:start'\n\nexport const TASK_LZ_TEST_SIMULATION_LOGS = 'lz:test:simulation:logs'\n\nexport const TASK_LZ_TEST_SIMULATION_STOP = 'lz:test:simulation:stop'\n","import type { HardhatRuntimeEnvironment, EthereumProvider, ConfigurableTaskDefinition } from 'hardhat/types'\n\nimport pMemoize from 'p-memoize'\nimport type { JsonRpcProvider } from '@ethersproject/providers'\nimport { ConfigurationError } from './errors'\nimport { HardhatContext } from 'hardhat/internal/context'\nimport { Environment as HardhatRuntimeEnvironmentImplementation } from 'hardhat/internal/core/runtime-environment'\nimport { EndpointId } from '@layerzerolabs/lz-definitions'\nimport { EndpointBasedFactory, Factory, formatEid } from '@layerzerolabs/devtools'\nimport { EthersProviderWrapper } from '@nomiclabs/hardhat-ethers/internal/ethers-provider-wrapper'\nimport assert from 'assert'\nimport memoize from 'micro-memoize'\nimport { subtask, task } from 'hardhat/config'\n\n/**\n * Helper type for when we need to grab something asynchronously by the network name\n */\nexport type GetByNetwork<TValue> = Factory<[networkName: string], TValue>\n\n/**\n * Helper type for when we need to grab something asynchronously by the network name\n */\nexport type GetByEid<TValue> = Factory<[eid: EndpointId], TValue>\n\n/**\n * Returns the default hardhat context for the project, i.e.\n * the context that the project has been setup with.\n *\n * Throws if there is no context.\n *\n * @returns {HardhatContext}\n */\nexport const getDefaultContext = (): HardhatContext => {\n    // Context is registered globally as a singleton and can be accessed\n    // using the static methods of the HardhatContext class\n    //\n    // In our case we require the context to exist, the other option would be\n    // to create it and set it up - see packages/hardhat-core/src/register.ts for an example setup\n    try {\n        return HardhatContext.getHardhatContext()\n    } catch (error: unknown) {\n        throw new ConfigurationError(`Could not get Hardhat context: ${error}`)\n    }\n}\n\n/**\n * Returns the default `HardhatRuntimeEnvironment` (`hre`) for the project.\n *\n * Throws if there is no `HardhatRuntimeEnvironment`.\n *\n * @returns {HardhatRuntimeEnvironment}\n */\nexport const getDefaultRuntimeEnvironment = (): HardhatRuntimeEnvironment => {\n    // The first step is to get the hardhat context\n    const context = getDefaultContext()\n\n    // We require the hardhat environment to already exist\n    //\n    // Again, we could create it but that means we'd need to duplicate the bootstrap code\n    // that hardhat does when setting up the environment\n    try {\n        return context.getHardhatRuntimeEnvironment()\n    } catch (error: unknown) {\n        throw new ConfigurationError(`Could not get Hardhat Runtime Environment: ${error}`)\n    }\n}\n\n/**\n * Creates a clone of the HardhatRuntimeEnvironment for a particular network\n *\n * ```typescript\n * const env = getHreByNetworkName(\"bsc-testnet\");\n *\n * // All the ususal properties are present\n * env.deployments.get(\"MyContract\")\n * ```\n *\n * @returns {Promise<HardhatRuntimeEnvironment>}\n */\nexport const getHreByNetworkName: GetByNetwork<HardhatRuntimeEnvironment> = pMemoize(async (networkName) => {\n    const context = getDefaultContext()\n    const environment = getDefaultRuntimeEnvironment()\n\n    try {\n        // The last step is to create a duplicate enviornment that mimics the original one\n        // with one crucial difference - the network setup\n        return new HardhatRuntimeEnvironmentImplementation(\n            environment.config,\n            {\n                ...environment.hardhatArguments,\n                network: networkName,\n            },\n            environment.tasks,\n            environment.scopes,\n            context.environmentExtenders,\n            context.experimentalHardhatNetworkMessageTraceHooks,\n            environment.userConfig,\n            context.providerExtenders\n            // This is a bit annoying - the environmentExtenders are not stronly typed\n            // so TypeScript complains that the properties required by HardhatRuntimeEnvironment\n            // are not present on HardhatRuntimeEnvironmentImplementation\n        ) as unknown as HardhatRuntimeEnvironment\n    } catch (error: unknown) {\n        throw new ConfigurationError(`Could not setup Hardhat Runtime Environment: ${error}`)\n    }\n})\n\n/**\n * Creates a clone of the HardhatRuntimeEnvironment for a particular network\n * identified by endpoint ID\n *\n * ```typescript\n * const getHreByEid = createGetHreByEid()\n * const env = await getHreByEid(EndpointId.AVALANCHE_V2_TESTNET);\n *\n * // All the ususal properties are present\n * env.deployments.get(\"MyContract\")\n * ```\n *\n * @returns {Promise<HardhatRuntimeEnvironment>}\n */\nexport const createGetHreByEid = (\n    hre = getDefaultRuntimeEnvironment()\n): EndpointBasedFactory<HardhatRuntimeEnvironment> =>\n    pMemoize(async (eid: EndpointId) => getHreByNetworkName(getNetworkNameForEid(eid, hre)))\n\n/**\n * Helper function that wraps an EthereumProvider with EthersProviderWrapper\n * so that we can use it further with ethers as a regular JsonRpcProvider\n *\n * @param {EIP1193Provider} provider\n * @returns {JsonRpcProvider}\n */\nexport const wrapEIP1193Provider = (provider: EthereumProvider): JsonRpcProvider => new EthersProviderWrapper(provider)\n\n/**\n * Gets an EndpointId defined in the hardhat config\n * for a particular network name (as an `eid` property).\n *\n * Throws if the network or the eid are not defined\n *\n * @param {string} networkName\n * @param {HardhatRuntimeEnvironment | undefined} [hre]\n * @returns {EndpointId}\n */\nexport const getEidForNetworkName = (\n    networkName: string,\n    hre: HardhatRuntimeEnvironment = getDefaultRuntimeEnvironment()\n): EndpointId => {\n    const networkConfig = hre.config.networks[networkName]\n    assert(networkConfig, `Network '${networkName}' is not defined in hardhat config`)\n    assert(networkConfig.eid != null, `Network '${networkName}' does not have 'eid' property defined in its config`)\n\n    return networkConfig.eid\n}\n\n/**\n * Gets a network name with its `eid` property matching\n * a particular `eid`\n *\n * Throws if there is no such network or if there are multiple\n * networks defined with the same `eid`\n *\n * @param {EndpointId} eid\n * @param {HardhatRuntimeEnvironment | undefined} [hre]\n * @returns {string}\n */\nexport const getNetworkNameForEid = (\n    eid: EndpointId,\n    hre: HardhatRuntimeEnvironment = getDefaultRuntimeEnvironment()\n): string => {\n    // We are using getEidsByNetworkName to get the nice validation of network config\n    const eidsByNetworkName = getEidsByNetworkName(hre)\n\n    for (const [networkName, networkEid] of Object.entries(eidsByNetworkName)) {\n        if (networkEid === eid) {\n            return networkName\n        }\n    }\n\n    // Here we error out if there are no networks with this eid\n    assert(false, `Could not find a network for eid ${eid} (${formatEid(eid)})`)\n}\n\n/**\n * Gets a record containing the mapping between network names and endpoint IDs.\n * Will also return the network names for which the `eid` has not been defined\n *\n * Throws if there are multiple networks defined with the same `eid`\n *\n * @param {HardhatRuntimeEnvironment | undefined} [hre]\n * @returns {Record<string, EndpointId | undefined>}\n */\nexport const getEidsByNetworkName = memoize(\n    (hre: HardhatRuntimeEnvironment = getDefaultRuntimeEnvironment()): Record<string, EndpointId | undefined> => {\n        // First we get the network name -> network config pairs\n        const networkEntries = Object.entries(hre.config.networks)\n        // And map the network config to an endpoint ID\n        const eidEntries = networkEntries.map(\n            ([networkName, networkConfig]) => [networkName, networkConfig.eid] as const\n        )\n        // Now we turn the entries back into a record\n        const eidsByNetworkName = Object.fromEntries(eidEntries)\n\n        // Now we check that the user has not configured the endpoint ID mapping incorrectly\n        // (i.e. there are more networks configured with the same endpoint ID)\n        //\n        // For this we'll drop all the networks whose endpoint IDs are not defined\n        const eidEntriesWithDefinedEid = eidEntries.filter(([_, eid]) => eid != null)\n        const definedEidsByNetworkName = Object.fromEntries(eidEntriesWithDefinedEid)\n\n        // Now we grab the sets of unique network names and endpoint IDs\n        const allDefinedEids = new Set(Object.values(definedEidsByNetworkName))\n        const allNetworkNames = new Set(Object.keys(definedEidsByNetworkName))\n\n        // If the number of unique networks matches the number of unique endpoint IDs, there are no duplicates\n        if (allDefinedEids.size === allNetworkNames.size) {\n            return eidsByNetworkName\n        }\n\n        // At this point the number of defined endpoint IDs can only be lower than\n        // the number of defined network names (since network names are taken from the keys\n        // of an object and endpoint IDs from its values)\n        //\n        // To let the user know whihc networks to fix, we need to grab all the ones that\n        // have been duplicated\n        //\n        // We are not claiming any efficiency of this algorithm as we don't expect any large numbers of networks\n        const duplicatedNetworkNames = Array.from(allDefinedEids)\n            // First we grab all the network names with this endpoint ID\n            .map((eid) =>\n                eidEntriesWithDefinedEid.flatMap(([networkName, definedEid]) =>\n                    eid === definedEid ? [networkName] : []\n                )\n            )\n            // Then we find all the network names listed more than once\n            .filter((networkNames) => networkNames.length > 1)\n\n        // Now we let the user know which network names have identical endpoint IDs\n        const messages = duplicatedNetworkNames\n            .map(\n                (networkNames) =>\n                    `- ${networkNames.join(', ')} have eid set to ${formatEid(eidsByNetworkName[networkNames[0]!]!)}`\n            )\n            .join('\\n')\n\n        throw new Error(\n            `Found multiple networks configured with the same 'eid':\\n\\n${messages}\\n\\nPlease fix this in your hardhat config.`\n        )\n    }\n)\n\n/**\n * Helper utility that copies the whole task definition under a new name\n *\n * This is useful if a new task needs to have the same interface as an existing task,\n * for example if we want to create a slightly modified version of a wire task\n * without needing to retype all the `.addFlag` and `.addOption`\n *\n * @param {string} parentTaskName Task to inherit the options and the action from\n * @param {HardhatRuntimeEnvironment} [hre]\n * @returns {(taskName: string) => ConfigurableTaskDefinition}\n */\nexport const inheritTask =\n    (parentTaskName: string, context = getDefaultContext()) =>\n    (taskName: string): ConfigurableTaskDefinition => {\n        // For now we only support non-scoped tasks\n        const parentTaskDefinition = context.tasksDSL.getTaskDefinition(undefined, parentTaskName)\n        assert(parentTaskDefinition != null, `Missing task definition for ${parentTaskName}`)\n\n        // First we create the task definition itself\n        const creator = parentTaskDefinition.isSubtask ? subtask : task\n        const childTask = creator(taskName).setAction(parentTaskDefinition.action)\n\n        // Then we start setting properties\n        if (parentTaskDefinition.description != null) {\n            childTask.setDescription(parentTaskDefinition.description)\n        }\n\n        // Params go first (just because I said so, not for any particular reason)\n        for (const definition of Object.values(parentTaskDefinition.paramDefinitions)) {\n            // Params need to be treated based on their type (flag/param)\n            if (definition.isFlag) {\n                childTask.addFlag(definition.name, definition.description)\n            } else {\n                childTask.addParam(\n                    definition.name,\n                    definition.description,\n                    definition.defaultValue,\n                    definition.type,\n                    definition.isOptional\n                )\n            }\n        }\n\n        // Positional params go second\n        for (const definition of parentTaskDefinition.positionalParamDefinitions) {\n            if (definition.isVariadic) {\n                childTask.addVariadicPositionalParam(\n                    definition.name,\n                    definition.description,\n                    definition.defaultValue,\n                    definition.type,\n                    definition.isOptional\n                )\n            } else {\n                childTask.addPositionalParam(\n                    definition.name,\n                    definition.description,\n                    definition.defaultValue,\n                    definition.type,\n                    definition.isOptional\n                )\n            }\n        }\n\n        return childTask\n    }\n","'use strict'\n\nexport class ConfigurationError extends Error {}\n","import { getDefaultRuntimeEnvironment } from '@/runtime'\nimport { Artifacts } from 'hardhat/internal/artifacts'\nimport { Artifact } from 'hardhat/types'\nimport pMemoize from 'p-memoize'\n\n/**\n * Will return all artifacts available in the project, including the external ones\n *\n * @return {Promise<Artifact[]>}\n */\nexport const getAllArtifacts = pMemoize(async (hre = getDefaultRuntimeEnvironment()): Promise<Artifact[]> => {\n    // First we collect all the paths where artifacts could be\n    //\n    // This is a port of the code found in hardhat-deploy/src/DeploymentsManager.ts\n    const externalContracts = hre.config.external?.contracts ?? []\n    const artifactsPaths: string[] = [\n        hre.config.paths.artifacts,\n        hre.config.paths.imports,\n        ...externalContracts.flatMap(({ artifacts }) => artifacts),\n    ]\n\n    // Now we create Artifacts objects\n    const artifactsObjects = artifactsPaths.map((path) => new Artifacts(path))\n\n    // Oxford dictionary defines \"artifactses\" as the plural form of \"artifacts\"\n    const artifactses = await Promise.all(artifactsObjects.map(getAllArtifactsFrom))\n\n    return artifactses.flat()\n})\n\nconst getAllArtifactsFrom = async (artifactsObject: Artifacts) => {\n    // First we get all the fully qualified names fro mthis artifacts object\n    const fullyQualifiedNames = await artifactsObject.getAllFullyQualifiedNames()\n\n    return fullyQualifiedNames.map((name) => artifactsObject.readArtifactSync(name))\n}\n\nexport const isErrorFragment = <TFragment extends { type?: string }>(\n    fragment: TFragment\n): fragment is TFragment & { type: 'error' } => fragment.type === 'error'\n","import { getAllArtifacts, isErrorFragment } from '@/artifacts'\nimport { Contract } from '@ethersproject/contracts'\nimport { OmniContract, createContractErrorParser } from '@layerzerolabs/devtools-evm'\nimport { makeZeroAddress } from '@layerzerolabs/devtools-evm'\nimport { EndpointId } from '@layerzerolabs/lz-definitions'\nimport pMemoize from 'p-memoize'\n\n/**\n * Helper function that combines all the available ABIs into a one giant\n * interface (only containing the error fragments) used for error decoding.\n *\n * @returns {OmniContract}\n */\nconst createCombinedContract = pMemoize(async (): Promise<OmniContract> => {\n    // We get all the available artifacts first\n    const artifacts = await getAllArtifacts()\n\n    // Now we combine the ABIs and keep only the errors\n    const abi = artifacts.flatMap((artifact) => artifact.abi).filter(isErrorFragment)\n\n    // Even though duplicated fragments don't throw errors, they still pollute the interface with warning console.logs\n    // To prevent this, we'll run a simple deduplication algorithm - use JSON encoded values as hashes\n    const deduplicatedAbi = Object.values(Object.fromEntries(abi.map((abi) => [JSON.stringify(abi), abi])))\n\n    // FIXME Since we are creating an endpoint-agnostic, completely fictional contract,\n    // we just make up and eid for it. Once the underlying logic is refactored, this should be gone\n    return { eid: -1 as EndpointId, contract: new Contract(makeZeroAddress(), deduplicatedAbi) }\n})\n\n/**\n * Creates a generic error parser based on all the artifacts found in your hardhat project\n */\nexport const createErrorParser = async () => createContractErrorParser(await createCombinedContract())\n","import { types as builtInTypes } from 'hardhat/config'\nimport { HardhatError } from 'hardhat/internal/core/errors'\nimport { ERRORS } from 'hardhat/internal/core/errors-list'\nimport type { CLIArgumentType } from 'hardhat/types'\nimport { splitCommaSeparated } from '@layerzerolabs/devtools'\nimport { isEVMAddress, SignerDefinition } from '@layerzerolabs/devtools-evm'\nimport { isLogLevel, LogLevel } from '@layerzerolabs/io-devtools'\nimport { Environment, Stage } from '@layerzerolabs/lz-definitions'\n\n/**\n * Hardhat CLI type for a comma separated list of arbitrary strings\n */\nconst csv: CLIArgumentType<string[]> = {\n    name: 'csv',\n    parse(name: string, value: string) {\n        return splitCommaSeparated(value)\n    },\n    validate() {},\n}\n\nconst isEnvironment = (value: string): value is Environment => Object.values<string>(Environment).includes(value)\n\n/**\n * Hardhat CLI type for a LayzerZero chain environment\n *\n * @see {@link Environment}\n */\nconst environment: CLIArgumentType<Environment> = {\n    name: 'environment',\n    parse(name: string, value: string) {\n        if (!isEnvironment(value)) {\n            throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {\n                value,\n                name: name,\n                type: 'environment',\n            })\n        }\n\n        return value\n    },\n    validate() {},\n}\n\nconst isStage = (value: string): value is Stage => Object.values<string>(Stage).includes(value)\n\n/**\n * Hardhat CLI type for a LayzerZero chain stage\n *\n * @see {@link Stage}\n */\nconst stage: CLIArgumentType<Stage> = {\n    name: 'stage',\n    parse(name: string, value: string) {\n        if (!isStage(value)) {\n            throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {\n                value,\n                name: name,\n                type: 'stage',\n            })\n        }\n\n        return value\n    },\n    validate() {},\n}\n\n/**\n * Hardhat CLI type for a log level argument\n *\n * @see {@link LogLevel}\n */\nconst logLevel: CLIArgumentType<LogLevel> = {\n    name: 'logLevel',\n    parse(name: string, value: string) {\n        if (!isLogLevel(value)) {\n            throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {\n                value,\n                name: name,\n                type: 'logLevel',\n            })\n        }\n\n        return value\n    },\n    validate() {},\n}\n\n/**\n * Hardhat CLI type for a function argument.\n *\n * This is only to be used with subtasks since you cannot pass functions\n * to tasks (unless you're insane and want to inline a function)\n */\nexport const fn: CLIArgumentType<string> = {\n    name: 'function',\n    parse: (argName, value) => {\n        if (typeof value !== 'function') {\n            throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {\n                value,\n                name: argName,\n                type: fn.name,\n            })\n        }\n\n        return value\n    },\n    validate() {},\n}\n\n/**\n * Signer-specific CLI argument (either a non-negative index\n * or a signer EVM address)\n */\nexport const signer: CLIArgumentType<SignerDefinition> = {\n    name: 'signer',\n    parse: (argName, value) => {\n        // If the value looks like an EVM address, we'll return an address definition\n        if (isEVMAddress(value)) {\n            return { type: 'address', address: value }\n        }\n\n        // If the value parses to an integer, we'll return an index definition\n        const parsed = parseInt(value, 10)\n        if (!isNaN(parsed)) {\n            if (parsed < 0) {\n                throw new HardhatError(ERRORS.ARGUMENTS.INVALID_VALUE_FOR_TYPE, {\n                    value,\n                    name: argName,\n                    type: signer.name,\n                })\n            }\n\n            return { type: 'index', index: parsed }\n        }\n\n        // In any other case we'll return a named definition\n        return { type: 'named', name: value }\n    },\n    validate() {},\n}\n\nexport const types = { csv, logLevel, fn, signer, environment, stage, ...builtInTypes }\n","import { getDefaultRuntimeEnvironment, getEidsByNetworkName } from '@/runtime'\nimport assert, { AssertionError } from 'assert'\nimport 'hardhat-deploy/dist/src/type-extensions'\nimport { DeploymentsExtension } from 'hardhat-deploy/dist/types'\nimport { HardhatRuntimeEnvironment } from 'hardhat/types'\n\nexport interface HardhatRuntimeEnvironmentWithDeployments extends HardhatRuntimeEnvironment {\n    deployments: DeploymentsExtension\n}\n\n/**\n * Helper utility to make sure hardhat-deploy is being used by the project\n *\n * @param {HardhatRuntimeEnvironment} hre\n */\nexport function assertHardhatDeploy(\n    hre: HardhatRuntimeEnvironment\n): asserts hre is HardhatRuntimeEnvironmentWithDeployments {\n    assert(hre.deployments, `You don't seem to be using hardhat-deploy in your project`)\n}\n\n/**\n * Helper utility to make sure that all the networks passed\n * to this function have been defined in the config\n *\n * @param {Iterable<string>} networkNames\n * @param {HardhatRuntimeEnvironment} hre\n */\nexport function assertDefinedNetworks<TNetworkNames extends Iterable<string>>(\n    networkNames: TNetworkNames,\n    hre: HardhatRuntimeEnvironment = getDefaultRuntimeEnvironment()\n): TNetworkNames {\n    const definedNetworkNames = new Set(Object.keys(getEidsByNetworkName(hre)))\n\n    for (const networkName of networkNames) {\n        if (definedNetworkNames.has(networkName)) {\n            continue\n        }\n\n        throw new AssertionError({\n            message: `Network '${networkName}' has not been defined. Defined networks are ${Array.from(definedNetworkNames).join(', ')}`,\n        })\n    }\n\n    return networkNames\n}\n","import 'hardhat/types/config'\nimport { EndpointId } from '@layerzerolabs/lz-definitions'\nimport { ConnectSafeConfigWithSafeAddress } from '@safe-global/protocol-kit'\nimport { SimulationUserConfig } from '@/simulation/types'\n\ndeclare module 'hardhat/types/config' {\n    interface HardhatNetworkUserConfig {\n        eid?: never\n        safeConfig?: never\n    }\n\n    interface HardhatNetworkConfig {\n        eid?: never\n        safeConfig?: never\n    }\n\n    interface HttpNetworkUserConfig {\n        /**\n         * Specifies the mapping between the network\n         * defined in your hardhat config and the LayerZero endpoint ID\n         * on this network.\n         *\n         * This allows you to use arbitrary network names while maintaining\n         * allowing you to easily find deployment and artifact information\n         * for LayerZero protocol contracts using the standard hardhat deploy methods\n         */\n        eid?: EndpointId\n\n        /**\n         * Use a \"local\" LayerZero environment for the network.\n         *\n         * Local environments are postfixed with `-local` in the deployment directories\n         * and represent contracts deployed to ephemerous development networks.\n         *\n         * Local environments cannot coexists with their non-local counterparts\n         * in hardhat configs since they share the same `eid`\n         */\n        isLocalEid?: boolean\n\n        /**\n         * Optional gnosis safe config.\n         */\n        safeConfig?: SafeConfig\n    }\n\n    interface HttpNetworkConfig {\n        /**\n         * Specifies the mapping between the network\n         * defined in your hardhat config and the LayerZero endpoint ID\n         * on this network.\n         *\n         * This allows you to use arbitrary network names while maintaining\n         * allowing you to easily find deployment and artifact information\n         * for LayerZero protocol contracts using the standard hardhat deploy methods\n         */\n        eid?: EndpointId\n\n        /**\n         * Use a \"local\" LayerZero environment for the network.\n         *\n         * Local environments are postfixed with `-local` in the deployment directories\n         * and represent contracts deployed to ephemerous development networks\n         *\n         * Local environments cannot coexists with their non-local counterparts\n         * in hardhat configs since they share the same `eid`\n         */\n        isLocalEid?: boolean\n\n        /**\n         * Optional gnosis safe config.\n         */\n        safeConfig?: SafeConfig\n    }\n    interface SafeConfig extends ConnectSafeConfigWithSafeAddress {\n        safeUrl: string\n        safeAddress: string // override to make ConnectSafeConfig.safeAddress mandatory\n    }\n\n    interface HardhatUserConfig {\n        /**\n         * LayerZero advanced configuration\n         */\n        layerZero?: LayerZeroHardhatUserConfig\n    }\n\n    interface LayerZeroHardhatUserConfig {\n        /**\n         * Defines the names of @layerzerolabs packages\n         * that will be added to your hardhat config under external deployments.\n         *\n         * By default, the protocol deployments from `@layerzerolabs/lz-evm-sdk-v2`\n         * will be added which allows your scripts to reference deployments\n         * of protocol contracts such as `EndpointV2`:\n         *\n         * ```\n         * // In your deploy script or task\n         * const { address, abi } = hre.deployments.get('EndpointV2')\n         * ```\n         *\n         * @default ['@layerzerolabs/lz-evm-sdk-v2']\n         */\n        deploymentSourcePackages?: string[]\n\n        /**\n         * Defines the names of @layerzerolabs packages\n         * that will be added to your hardhat config under external artifacts.\n         *\n         * By default, the protocol artifacts from `@layerzerolabs/lz-evm-sdk-v2`\n         * will be added which allows your scripts to reference artifacts\n         * of protocol contracts such as `EndpointV2`:\n         *\n         * ```\n         * // In your deploy script or task\n         * const { address, abi } = hre.deployments.get('EndpointV2')\n         * ```\n         *\n         * For testing purposes, artifacts from `@layerzerolabs/test-devtools-evm-hardhat`\n         * will also be added. This allows your tests to reference contracts such as `EndpointV2Mock`:\n         *\n         * ```\n         * // In your hardhat test\n         * const EndpointV2MockArtifact = await hre.deployments.getArtifact('EndpointV2Mock')\n         * ```\n         *\n         * @default ['@layerzerolabs/lz-evm-sdk-v2','@layerzerolabs/test-devtools-evm-hardhat']\n         */\n        artifactSourcePackages?: string[]\n\n        /**\n         * Configuration of features that are not considered stable yet\n         */\n        experimental?: {\n            /**\n             * Configuration for omnichain simulation\n             *\n             * Omnichain simulation allows developers to easily setup\n             * local environment forked from live networks without\n             * having to adjust the `hardhat.config.ts` file\n             */\n            simulation?: SimulationUserConfig\n        }\n    }\n}\n","import '@/type-extensions'\n\nimport { TASK_LZ_TEST_SIMULATION_LOGS, TASK_LZ_TEST_SIMULATION_START } from '@/constants'\nimport { ActionType } from 'hardhat/types'\nimport { task } from 'hardhat/config'\nimport { printLogo } from '@layerzerolabs/io-devtools/swag'\nimport { LogLevel, createLogger, isFile, printJson, setDefaultLogLevel } from '@layerzerolabs/io-devtools'\nimport { types } from '@/cli'\nimport { resolveSimulationConfig } from '@/simulation/config'\nimport { join } from 'path'\nimport { spawnSync } from 'child_process'\n\nexport interface SimulationLogsTaskArgs {\n    logLevel?: LogLevel\n}\n\nconst action: ActionType<SimulationLogsTaskArgs> = async ({ logLevel = 'info' }, hre) => {\n    setDefaultLogLevel(logLevel)\n\n    printLogo()\n\n    const logger = createLogger()\n\n    // Grab the simulation user config from hardhat user config\n    const simulationUserConfig = hre.userConfig.layerZero?.experimental?.simulation ?? {}\n    logger.verbose(`Using simulation user config:\\n${printJson(simulationUserConfig)}`)\n\n    // Resolve the defaults for the simulation config\n    const simulationConfig = resolveSimulationConfig(simulationUserConfig, hre.config)\n    logger.verbose(`Resolved simulation config:\\n${printJson(simulationConfig)}`)\n\n    // Check that the docker compose file exists\n    const dockerComposePath = join(simulationConfig.directory, 'docker-compose.yaml')\n    if (!isFile(dockerComposePath)) {\n        logger.warn(`Could not find simulation docker compose file '${dockerComposePath}'`)\n        logger.warn(`Did you run 'npx hardhat ${TASK_LZ_TEST_SIMULATION_START}'?`)\n\n        process.exitCode = 1\n\n        return\n    }\n\n    // Spawn docker compose logs command, piping the stdout and stderr to the current shell\n    //\n    // The error reporting on this part should be improved - we should check that \"docker\" and \"docker compose\"\n    // are known commands before we go ahead and try executing them\n    try {\n        logger.verbose(`Spawning docker compose logs command for ${dockerComposePath}`)\n\n        spawnSync('docker', ['compose', '-f', dockerComposePath, 'logs'], {\n            stdio: 'inherit',\n        })\n    } catch (error) {\n        logger.error(`Failed to spawn docker compose logs command for ${dockerComposePath}: ${error}`)\n\n        process.exitCode = 1\n\n        return\n    }\n}\n\nif (process.env.LZ_ENABLE_EXPERIMENTAL_SIMULATION) {\n    task(TASK_LZ_TEST_SIMULATION_LOGS, 'Show logs for LayerZero omnichain simulation', action).addParam(\n        'logLevel',\n        'Logging level. One of: error, warn, info, verbose, debug, silly',\n        'info',\n        types.logLevel\n    )\n}\n","import type { HardhatConfig, HttpNetworkConfig, NetworkConfig } from 'hardhat/types'\nimport type { SimulationConfig, SimulationUserConfig } from './types'\nimport { resolve } from 'path'\nimport { AnvilOptions } from '@layerzerolabs/devtools-evm'\nimport { pipe } from 'fp-ts/lib/function'\nimport * as R from 'fp-ts/Record'\n\n/**\n * Turns `SimulationUserConfig` into `SimulationConfig` by supplying defaults\n *\n * @param {SimulationUserConfig} userConfig\n * @param {HardhatConfig} hardhatConfig\n * @returns {SimulationConfig}\n */\nexport const resolveSimulationConfig = (\n    userConfig: SimulationUserConfig,\n    hardhatConfig: HardhatConfig\n): SimulationConfig => ({\n    port: userConfig.port ?? 8545,\n    directory: resolve(hardhatConfig.paths.root, userConfig.directory ?? '.layerzero'),\n    anvil: {\n        // For now we'll hardcode the mnemonic we'll use to seed the accounts on the simulation networks\n        mnemonic: 'test test test test test test test test test test test junk',\n        ...userConfig.anvil,\n        // The host and port need to always point to 0.0.0.0:8545\n        // since anvil runs in the container that exposes this port on 0.0.0.0\n        host: '0.0.0.0',\n        port: 8545,\n    },\n})\n\n/**\n * Takes a portion of the hardhat networks config and turns the values into `AnvilOptions`\n * to be used by a simulation network container.\n *\n * This is used in the simulation generation phase where the compose files\n * for networks defined in hardhat config are being generated.\n *\n * The `Record<string, NetworkConfig>` is used instead of `NetworksConfig` type from hardhat\n * to avoid any type issues with special keys like `localhost` or `hardhat`.\n *\n * @param {SimulationConfig} config\n * @param {Record<string, NetworkConfig>} networksConfig\n * @returns {Record<string, AnvilOptions>} Object with the same keys as the networks config, with values mapped to `AnvilOptions`\n */\nexport const getAnvilOptionsFromHardhatNetworks = (\n    config: SimulationConfig,\n    networksConfig: Record<string, NetworkConfig>\n): Record<string, AnvilOptions> =>\n    pipe(\n        networksConfig,\n        // We want to drop all the networks that don't have URLs\n        R.filter(isHttpNetworkConfig),\n        // And map the network configs into AnvilOptions\n        R.map(\n            (networkConfig: HttpNetworkConfig): AnvilOptions => ({\n                ...config.anvil,\n                forkUrl: networkConfig.url,\n            })\n        )\n    )\n\n/**\n * Returns with overrides for hardhat network configuration.\n *\n * This, when merged with a hardhat config, will redirect the network calls to the local EVM nodes.\n *\n * @param {SimulationConfig} config\n * @param {Record<string, NetworkConfig>} networksConfig\n * @returns {Record<string, NetworkConfig>}\n */\nexport const getHardhatNetworkOverrides = (\n    config: SimulationConfig,\n    networksConfig: Record<string, NetworkConfig>\n): Record<string, NetworkConfig> =>\n    pipe(\n        networksConfig,\n        // We want to drop all the networks that don't have URLs\n        R.filter(isHttpNetworkConfig),\n        // We'll take the existing network configs and point them to our RPC proxy\n        //\n        // It's important that these configs are not saved to filesystem as they might contain\n        // sensitive data (and forgetting to ignore these files in git could lead to security breaches)\n        R.mapWithIndex(\n            (networkName, networkConfig): NetworkConfig => ({\n                ...networkConfig,\n                // We want to redirect this network to the local proxy\n                //\n                // This is the nginx server listening on the port we configured in the simulation configuration\n                url: new URL(networkName, `http://localhost:${config.port}`).toString(),\n                // For now the mnemonic in identical for all the networks and comes\n                // from the simulation configuration\n                //\n                // In future we could respect the mnemonics set in the original hardhat config\n                // but that comes with complexities:\n                //\n                // - Some networks / hardhat configs will not be using mnemonics\n                // - We don't want to be throwing production mnemonics around and storing them in json files\n                accounts: {\n                    mnemonic: config.anvil.mnemonic,\n                    // These need to be defaulted to the anvil options\n                    // (or the anvil defaults)\n                    //\n                    // See https://book.getfoundry.sh/reference/cli/anvil for anvil defaults\n                    count: config.anvil.count ?? 10,\n                    path: config.anvil.derivationPath ?? \"m/44'/60'/0'/0/\",\n                    // These will be hardcoded for now as anvil does not support setting these\n                    initialIndex: 0,\n                    passphrase: '',\n                },\n            })\n        )\n    )\n\n/**\n * Helper utility to pick network configs by their names / object keys.\n *\n * Similar to TypeScript `Pick` helper type, but in runtime.\n *\n * @param {string[]} networks List of networks to pick\n */\nexport const pickNetworkConfigs = (networks: string[]) =>\n    R.filterWithIndex<string, NetworkConfig>((networkName: string) => networks.includes(networkName))\n\n/**\n * Little helper utility that checks whether a network config is not a hardhat network config\n *\n * @param {NetworkConfig} networkConfig\n * @returns {boolean}\n */\nconst isHttpNetworkConfig = (networkConfig: NetworkConfig): networkConfig is HttpNetworkConfig =>\n    'url' in networkConfig && typeof networkConfig.url === 'string'\n","import '@/type-extensions'\n\nimport { TASK_LZ_TEST_SIMULATION_LOGS, TASK_LZ_TEST_SIMULATION_START } from '@/constants'\nimport { ActionType } from 'hardhat/types'\nimport { task } from 'hardhat/config'\nimport { types } from '@/cli'\nimport { printLogo } from '@layerzerolabs/io-devtools/swag'\nimport { LogLevel, createLogger, printJson, setDefaultLogLevel } from '@layerzerolabs/io-devtools'\nimport { mkdirSync, writeFileSync } from 'fs'\nimport { join } from 'path'\nimport { serializeDockerComposeSpec } from '@layerzerolabs/devtools'\nimport { createSimulationComposeSpec } from '@/simulation/compose'\nimport { assertDefinedNetworks } from '@/internal/assertions'\nimport { getEidsByNetworkName } from '@/runtime'\nimport { getAnvilOptionsFromHardhatNetworks, pickNetworkConfigs, resolveSimulationConfig } from '@/simulation'\nimport { dockerfile, nginxConf } from '@/simulation/assets'\nimport { spawnSync } from 'child_process'\n\nexport interface SimulationStartTaskArgs {\n    logLevel?: LogLevel\n    networks?: string[]\n    daemon?: boolean\n}\n\nconst action: ActionType<SimulationStartTaskArgs> = async (\n    { networks: networksArgument, daemon = false, logLevel = 'info' },\n    hre\n) => {\n    setDefaultLogLevel(logLevel)\n\n    printLogo()\n\n    const logger = createLogger()\n\n    // Let's grab the networks that will be included in the simulation\n    const networks = networksArgument\n        ? // Here we need to check whether the networks have been defined in hardhat config\n          assertDefinedNetworks(networksArgument)\n        : //  But here we are taking them from hardhat config so no assertion is necessary\n          Object.entries(getEidsByNetworkName(hre)).flatMap(([networkName, eid]) => (eid == null ? [] : [networkName]))\n\n    // We only continue if we have any networks with eid\n    //\n    // The eid is not really a requirement - we could spin up forked nodes for any\n    // network defined in the hardhat config - it's just a way of limiting this simulation to LayerZero networks\n    if (networks.length === 0) {\n        logger.warn(`No networks with eid configured, exiting`)\n\n        return\n    }\n\n    logger.info(`Will create a simulation configuration for networks ${networks.join(', ')}`)\n\n    // Grab the simulation user config from hardhat user config\n    const simulationUserConfig = hre.userConfig.layerZero?.experimental?.simulation ?? {}\n    logger.verbose(`Using simulation user config:\\n${printJson(simulationUserConfig)}`)\n\n    // Resolve the defaults for the simulation config\n    const simulationConfig = resolveSimulationConfig(simulationUserConfig, hre.config)\n    logger.verbose(`Resolved simulation config:\\n${printJson(simulationConfig)}`)\n\n    // Grab only the network configs we are going to need for the simulation\n    const networkConfigs = pickNetworkConfigs(networks)(hre.config.networks)\n\n    // Turn the network configs into anvil options\n    const anvilOptions = getAnvilOptionsFromHardhatNetworks(simulationConfig, networkConfigs)\n    logger.verbose(`The anvil config is:\\n${printJson(anvilOptions)}`)\n\n    // Now create the compose file\n    const composeSpec = createSimulationComposeSpec(simulationConfig, anvilOptions)\n    const serializedComposeSpec = serializeDockerComposeSpec(composeSpec)\n\n    // And finally we write all the required file artifacts to filesystem\n    logger.verbose(`Making sure directory ${simulationConfig.directory} exists`)\n    mkdirSync(simulationConfig.directory, { recursive: true })\n\n    const dockerfilePath = join(simulationConfig.directory, 'Dockerfile')\n    logger.debug(`Writing simulation Dockerfile to ${dockerfilePath}`)\n    writeFileSync(dockerfilePath, dockerfile)\n\n    const nginxConfPath = join(simulationConfig.directory, 'nginx.conf')\n    logger.debug(`Writing simulation nginx configuration file to ${nginxConfPath}`)\n    writeFileSync(nginxConfPath, nginxConf)\n\n    const dockerComposePath = join(simulationConfig.directory, 'docker-compose.yaml')\n    logger.debug(`Writing simulation docker compose spec file to ${dockerComposePath}`)\n    writeFileSync(dockerComposePath, serializedComposeSpec)\n\n    // Spawn docker compose up command, piping the stdout and stderr to the current shell\n    //\n    // The error reporting on this part should be improved - we should check that \"docker\" and \"docker compose\"\n    // are known commands before we go ahead and try executing them\n    try {\n        if (daemon) {\n            logger.info(`Starting simulation in the background`)\n            logger.info(\n                `Use 'LZ_ENABLE_EXPERIMENTAL_SIMULATION=1 npx hardhat ${TASK_LZ_TEST_SIMULATION_LOGS}' to view the network logs`\n            )\n        } else {\n            logger.info(`Starting simulation`)\n        }\n\n        logger.verbose(`Spawning docker compose up command for ${dockerComposePath}`)\n\n        // This is a very quick and dirty way to pass an optional --wait argument to docker compose up\n        const additionalUpArgs: string[] = daemon ? ['--wait'] : []\n\n        spawnSync('docker', ['compose', '-f', dockerComposePath, 'up', ...additionalUpArgs], {\n            stdio: 'inherit',\n        })\n    } catch (error) {\n        logger.error(`Failed to spawn docker compose up command for ${dockerComposePath}: ${error}`)\n\n        process.exitCode = 1\n\n        return\n    }\n}\n\nif (process.env.LZ_ENABLE_EXPERIMENTAL_SIMULATION) {\n    task(TASK_LZ_TEST_SIMULATION_START, 'Start LayzerZero omnichain simulation', action)\n        .addParam('logLevel', 'Logging level. One of: error, warn, info, verbose, debug, silly', 'info', types.logLevel)\n        .addParam('networks', 'Comma-separated list of networks to simulate', undefined, types.csv, true)\n        .addFlag('daemon', 'Start the simulation in the background')\n}\n","import { pipe } from 'fp-ts/lib/function'\nimport * as RR from 'fp-ts/ReadonlyRecord'\nimport type { ComposeSpec, ComposeSpecService } from '@layerzerolabs/devtools'\nimport { type AnvilOptions, createAnvilCliOptions } from '@layerzerolabs/devtools-evm'\nimport type { ComposeSpecServices } from '@layerzerolabs/devtools'\nimport type { SimulationConfig } from './types'\n\n/**\n * Creates a docker compose service specification for an anvil-based EVM node\n *\n * @param {AnvilOptions} anvilOptions\n * @returns {ComposeSpecService}\n */\nexport const createEvmNodeServiceSpec = (anvilOptions: AnvilOptions): ComposeSpecService => ({\n    // This service references a Dockerfile that is copied\n    // next to the resulting docker-compose.yaml\n    //\n    // The source for this Dockerfile is located in src/simulation/assets/Dockerfile.conf\n    build: {\n        dockerfile: 'Dockerfile',\n        target: 'node-evm',\n    },\n    command: ['anvil', ...createAnvilCliOptions(anvilOptions)],\n})\n\n/**\n * Creates a docker compose service specification for an nginx-based proxy service\n * that proxies requests to underlying EVM nodes (or their RPC URLs to be mor precise)\n *\n * @param {number} port\n * @param {ComposeSpecServices} networkServices\n * @returns {ComposeSpecService}\n */\nexport const createEvmNodeProxyServiceSpec = (\n    port: number,\n    networkServices: ComposeSpecServices\n): ComposeSpecService => ({\n    // This service references a Dockerfile that is copied\n    // next to the resulting docker-compose.yaml\n    //\n    // The source for this Dockerfile is located in src/simulation/assets/Dockerfile.conf\n    build: {\n        dockerfile: 'Dockerfile',\n        target: 'proxy-evm',\n    },\n    // This service will expose its internal 8545 port to a host port\n    //\n    // The internal 8545 port is hardcoded both here and in the nginx.conf file,\n    // the source for which is located in src/simulation/assets/nginx.conf\n    ports: [`${port}:8545`],\n    depends_on: pipe(\n        networkServices,\n        // This service will depend on the RPCs to be healthy\n        // so we'll take the networkServices object and replace\n        // the values with service_healthy condition\n        RR.map(() => ({\n            condition: 'service_healthy',\n        }))\n    ),\n})\n\n/**\n * Creates a docker compose spec with a set of anvil-based EVM nodes\n * and a single proxy server that proxies requests to these nodes.\n *\n * @param {SimulationConfig} config\n * @param {Record<string, AnvilOptions>} networks\n * @returns {ComposeSpec}\n */\nexport const createSimulationComposeSpec = (\n    config: SimulationConfig,\n    networks: Record<string, AnvilOptions>\n): ComposeSpec => ({\n    version: '3.9',\n    services: pipe(\n        networks,\n        // First we turn the networks into docker compose specs for EVM nodes\n        RR.map(createEvmNodeServiceSpec),\n        (networkServiceSpecs) =>\n            // Then we add the RPC proxy server\n            //\n            // There is a small edge case here that we can address\n            // if it ever comes up: if a network is called 'rpc', this compose file\n            // will not work.\n            //\n            // The fix for this is to prefix all networks with something like network-xxx\n            // but we can do that if ever this usecase comes up\n            pipe(\n                networkServiceSpecs,\n                RR.upsertAt('rpc', createEvmNodeProxyServiceSpec(config.port, networkServiceSpecs))\n            )\n    ),\n})\n","ARG FOUNDRY_VERSION=nightly-156cb1396b7076c6f9cb56f3719f8c90f7f52064\nARG ALPINE_VERSION=3.18\n\n#   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-\n#  / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\\n# `-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'\n#\n#             Image that gives us the foundry tools\n#\n#   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-\n#  / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\\n# `-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'\nFROM ghcr.io/foundry-rs/foundry:$FOUNDRY_VERSION AS foundry\n\n#   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-\n#  / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\\n# `-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'\n#\n#               Image that starts an EVM node\n#\n#   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-\n#  / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\\n# `-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'\nFROM alpine:$ALPINE_VERSION AS node-evm\n\nSTOPSIGNAL SIGINT\n\n# We will provide a default healthcheck (that assumes that the netowrk is running on the default port 8545)\nHEALTHCHECK --timeout=2s --interval=2s --retries=20 CMD cast block --rpc-url http://localhost:8545/ latest\n\n# Get anvil\nCOPY --from=foundry /usr/local/bin/anvil /usr/local/bin/anvil\n\n# Get cast for healthcheck\nCOPY --from=foundry /usr/local/bin/cast /usr/local/bin/cast\n\n#   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-\n#  / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\\n# `-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'\n#\n#           Image that starts an nginx proxy server\n#\n#   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-.   .-.-\n#  / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\ \\ / / \\\n# `-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'   `-`-'\nFROM nginx:alpine$ALPINE_VERSION AS proxy-evm\n\nCOPY ./nginx.conf /etc/nginx/nginx.conf\n\nHEALTHCHECK --timeout=2s --interval=2s --retries=20 CMD curl -f http://0.0.0.0:8545/health-check\n\n","events {}\n\nhttp {\n  # We will modify the log  format to include the target_network\n  log_format proxied '$remote_addr - $remote_user [$time_local] '\n                     '\"$request\" $status $body_bytes_sent '\n                     '\"$http_referer\" \"$http_user_agent\" '\n                     'Network: \"$target_network\"';\n\n  server {\n    # This proxy server will listen on port 8545\n    # \n    # Even though it's not ideal to have this hardcoded, this port\n    # will be remapped to a desired host port using docker compose,\n    # the only issue this hardcoding brings is the fact that this port\n    # needs to match the container port in the compose spec\n    listen 8545;\n    listen [::]:8545;\n\n    # We will add a simple endpoint for healthcheck\n    location /health-check {\n      access_log\toff;\n      error_log\toff;\n      return 200 'ok';\n    }\n\n    # In this section we'll proxy all the requests to this server\n    # to the respective network nodes\n    # \n    # The requests are proxied based on the first path segment:\n    # \n    # http://localhost/fuji -> http://fuji:8545/\n    # \n    # For now the remaining path segments are not being preserved:\n    # \n    # # http://localhost/fuji/some/url -> http://fuji:8545/\n    location / {\n      # Set the log format to be our custom 'proxied' log format\n      access_log /var/log/nginx/access.log proxied;\n\n      resolver 127.0.0.11;\n      autoindex off;\n\n      # This variable will hold the name of the network to proxy to\n      set $target_network '';\n\n      # Extract the first path segment from the request URI\n      if ($request_uri ~* ^/(?<target_network>[^/]+)(/.*)?$) {\n        set $target_network $1;\n      }\n\n      # Proxy the request to the appropriate network\n      proxy_pass http://$target_network:8545/;\n    }\n  }\n}","import '@/type-extensions'\n\nimport { TASK_LZ_TEST_SIMULATION_START, TASK_LZ_TEST_SIMULATION_STOP } from '@/constants'\nimport { ActionType } from 'hardhat/types'\nimport { task } from 'hardhat/config'\nimport { printLogo } from '@layerzerolabs/io-devtools/swag'\nimport { LogLevel, createLogger, isFile, printJson, setDefaultLogLevel } from '@layerzerolabs/io-devtools'\nimport { types } from '@/cli'\nimport { resolveSimulationConfig } from '@/simulation/config'\nimport { join } from 'path'\nimport { spawnSync } from 'child_process'\nimport { rmSync } from 'fs'\n\nexport interface SimulationStopTaskArgs {\n    logLevel?: LogLevel\n}\n\nconst action: ActionType<SimulationStopTaskArgs> = async ({ logLevel = 'info' }, hre) => {\n    setDefaultLogLevel(logLevel)\n\n    printLogo()\n\n    const logger = createLogger()\n\n    // Grab the simulation user config from hardhat user config\n    const simulationUserConfig = hre.userConfig.layerZero?.experimental?.simulation ?? {}\n    logger.verbose(`Using simulation user config:\\n${printJson(simulationUserConfig)}`)\n\n    // Resolve the defaults for the simulation config\n    const simulationConfig = resolveSimulationConfig(simulationUserConfig, hre.config)\n    logger.verbose(`Resolved simulation config:\\n${printJson(simulationConfig)}`)\n\n    // Check that the docker compose file exists\n    const dockerComposePath = join(simulationConfig.directory, 'docker-compose.yaml')\n    if (!isFile(dockerComposePath)) {\n        logger.warn(`Could not find simulation docker compose file '${dockerComposePath}'`)\n        logger.warn(`Did you run 'npx hardhat ${TASK_LZ_TEST_SIMULATION_START}'?`)\n\n        process.exitCode = 1\n\n        return\n    }\n\n    // Spawn docker compose down command, piping the stdout and stderr to the current shell\n    //\n    // The error reporting on this part should be improved - we should check that \"docker\" and \"docker compose\"\n    // are known commands before we go ahead and try executing them\n    try {\n        logger.info(`Stopping simulation`)\n        logger.verbose(`Spawning docker compose down command for ${dockerComposePath}`)\n\n        spawnSync('docker', ['compose', '-f', dockerComposePath, 'down'], {\n            stdio: 'inherit',\n        })\n    } catch (error) {\n        logger.error(`Failed to spawn docker compose down command for ${dockerComposePath}: ${error}`)\n\n        process.exitCode = 1\n\n        return\n    } finally {\n        try {\n            rmSync(simulationConfig.directory, { force: true, recursive: true })\n        } catch (error) {\n            logger.error(`Failed to delete '${simulationConfig.directory}': ${error}`)\n        }\n    }\n}\n\nif (process.env.LZ_ENABLE_EXPERIMENTAL_SIMULATION) {\n    task(TASK_LZ_TEST_SIMULATION_STOP, 'Stop LayerZero omnichain simulation', action).addParam(\n        'logLevel',\n        'Logging level. One of: error, warn, info, verbose, debug, silly',\n        'info',\n        types.logLevel\n    )\n}\n","import { formatOmniTransaction as formatOmniTransactionBase, type OmniTransaction } from '@layerzerolabs/devtools'\nimport { getNetworkNameForEid } from '@/runtime'\n\nexport const formatOmniTransaction = (\n    transaction: OmniTransaction\n): Record<string, string | number | bigint | undefined> => ({\n    Network: getNetworkNameForEid(transaction.point.eid),\n    ...formatOmniTransactionBase(transaction),\n})\n","import { types } from '@/cli'\nimport { SUBTASK_LZ_SIGN_AND_SEND } from '@/constants'\nimport { formatOmniTransaction } from '@/transactions/format'\nimport {\n    type OmniSignerFactory,\n    type OmniTransaction,\n    type OmniTransactionWithError,\n    type OmniTransactionWithReceipt,\n    type SignAndSendResult,\n    createSignAndSend,\n} from '@layerzerolabs/devtools'\nimport {\n    createLogger,\n    createModuleLogger,\n    pluralizeNoun,\n    printBoolean,\n    printJson,\n    promptToContinue,\n} from '@layerzerolabs/io-devtools'\nimport { createProgressBar, printRecords, render } from '@layerzerolabs/io-devtools/swag'\nimport { subtask } from 'hardhat/config'\nimport type { ActionType } from 'hardhat/types'\n\nexport interface SignAndSendTaskArgs {\n    ci?: boolean\n    transactions: OmniTransaction[]\n    createSigner: OmniSignerFactory\n}\n\nconst action: ActionType<SignAndSendTaskArgs> = async ({\n    ci,\n    transactions,\n    createSigner,\n}): Promise<SignAndSendResult> => {\n    // We only want to be asking users for input if we are not in interactive mode\n    const isInteractive = !ci\n\n    const logger = createLogger()\n    const subtaskLogger = createModuleLogger(SUBTASK_LZ_SIGN_AND_SEND)\n\n    // Ask them whether they want to see them\n    const previewTransactions = isInteractive\n        ? await promptToContinue(`Would you like to preview the transactions before continuing?`)\n        : true\n    if (previewTransactions) {\n        printRecords(transactions.map(formatOmniTransaction))\n    }\n\n    // Now ask the user whether they want to go ahead with signing them\n    //\n    // If they don't, we'll just return the list of pending transactions\n    const shouldSubmit = isInteractive\n        ? await promptToContinue(`Would you like to submit the required transactions?`)\n        : true\n    if (!shouldSubmit) {\n        return subtaskLogger.verbose(`User cancelled the operation, exiting`), [[], [], transactions]\n    }\n\n    subtaskLogger.verbose(`Signing and sending transactions:\\n\\n${printJson(transactions)}`)\n\n    // The last step is to execute those transactions\n    //\n    // For now we are only allowing sign & send using the accounts confgiured in hardhat config\n    const signAndSend = createSignAndSend(createSigner)\n\n    // We'll use these variables to store the state of signing\n    let transactionsToSign: OmniTransaction[] = transactions\n    let successfulTransactions: OmniTransactionWithReceipt[] = []\n    let errors: OmniTransactionWithError[] = []\n\n    // We will run an infinite retry loop when signing the transactions\n    //\n    // This loop will be broken in these scenarios:\n    // - if all the transactions succeed\n    // - if some of the transactions fail\n    //      - in the interactive mode, if the user decides not to retry the failed transactions\n    //      - in the non-interactive mode\n    //\n    // eslint-disable-next-line no-constant-condition\n    while (true) {\n        // Now we render a progressbar to monitor the task progress\n        const progressBar = render(\n            createProgressBar({ before: 'Signing... ', after: ` 0/${transactionsToSign.length}` })\n        )\n\n        subtaskLogger.verbose(`Sending the transactions`)\n        const [successfulBatch, errorsBatch, pendingBatch] = await signAndSend(\n            transactionsToSign,\n            (result, results) => {\n                // We'll keep updating the progressbar as we sign the transactions\n                progressBar.rerender(\n                    createProgressBar({\n                        progress: results.length / transactionsToSign.length,\n                        before: 'Signing... ',\n                        after: ` ${results.length}/${transactionsToSign.length}`,\n                    })\n                )\n            }\n        )\n\n        // And finally we drop the progressbar and continue\n        progressBar.clear()\n\n        // Now let's update the accumulators\n        //\n        // We'll append the successful transactions\n        successfulTransactions = [...successfulTransactions, ...successfulBatch]\n        // Overwrite the errrors\n        //\n        // We might in future return the error history but for now the last errors are okay\n        errors = errorsBatch\n        // And we update the array of transactions with the ones that did not make it through\n        transactionsToSign = pendingBatch\n\n        subtaskLogger.verbose(`Sent the transactions`)\n        subtaskLogger.debug(`Successfully sent the following transactions:\\n\\n${printJson(successfulBatch)}`)\n        subtaskLogger.debug(`Failed to send the following transactions:\\n\\n${printJson(errorsBatch)}`)\n        subtaskLogger.debug(`Did not send the following transactions:\\n\\n${printJson(pendingBatch)}`)\n\n        // Let the user know about the results of the batch\n        logger.info(\n            pluralizeNoun(\n                successfulBatch.length,\n                `Successfully sent 1 transaction`,\n                `Successfully sent ${successfulBatch.length} transactions`\n            )\n        )\n\n        // If there are no errors, we break out of the loop immediatelly\n        if (errors.length === 0) {\n            logger.info(`${printBoolean(true)} Your OApp is now configured`)\n\n            break\n        }\n\n        // Now we bring the bad news to the user\n        logger.error(\n            pluralizeNoun(errors.length, `Failed to send 1 transaction`, `Failed to send ${errors.length} transactions`)\n        )\n\n        const previewErrors = isInteractive\n            ? await promptToContinue(`Would you like to preview the failed transactions?`)\n            : true\n        if (previewErrors) {\n            printRecords(\n                errors.map(({ error, transaction }) => ({\n                    error: String(error),\n                    ...formatOmniTransaction(transaction),\n                }))\n            )\n        }\n\n        // We'll ask the user if they want to retry if we're in interactive mode\n        //\n        // If they decide not to, we exit, if they want to retry we start the loop again\n        const retry = isInteractive ? await promptToContinue(`Would you like to retry?`, true) : false\n        if (!retry) {\n            logger.error(`${printBoolean(false)} Failed to configure the OApp`)\n\n            break\n        }\n    }\n\n    return [successfulTransactions, errors, transactionsToSign]\n}\n\nsubtask(SUBTASK_LZ_SIGN_AND_SEND, 'Sign and send a list of transactions using a local signer', action)\n    .addFlag('ci', 'Continuous integration (non-interactive) mode. Will not ask for any input from the user')\n    .addParam('transactions', 'List of OmniTransaction objects', undefined, types.any)\n    .addParam('createSigner', 'Function that creates a signer for a particular network', undefined, types.fn)\n","import { task } from 'hardhat/config'\nimport type { ActionType } from 'hardhat/types'\nimport { TASK_LZ_EXPORT_DEPLOYMENTS_TYPESCRIPT } from '@/constants/tasks'\nimport { OutputFile, createIncludeDirent, generate, generatorTypeScript } from '@layerzerolabs/export-deployments'\nimport { createLogger, pluralizeNoun, printBoolean, setDefaultLogLevel } from '@layerzerolabs/io-devtools'\n\nimport { printLogo } from '@layerzerolabs/io-devtools/swag'\nimport { types } from '@/cli'\n\ninterface TaskArgs {\n    contracts?: string[]\n    networks?: string[]\n    outDir?: string\n    logLevel?: string\n}\n\nconst action: ActionType<TaskArgs> = async (\n    { networks, contracts, logLevel = 'info', outDir = 'generated' },\n    hre\n): Promise<OutputFile[]> => {\n    printLogo()\n\n    // We'll set the global logging level to get as much info as needed\n    setDefaultLogLevel(logLevel)\n\n    // And we'll create a logger for ourselves\n    const logger = createLogger()\n\n    // We just go ahead and export, not a care in the world\n    const results = generate({\n        // Since we are in a hardhat project, the deployments path is coming from the config\n        deploymentsDir: hre.config.paths.deployments,\n        outDir,\n        includeDeploymentFile: createIncludeDirent(contracts),\n        includeNetworkDir: createIncludeDirent(networks),\n        generator: generatorTypeScript,\n    })\n\n    logger.info(\n        `${printBoolean(true)} ${pluralizeNoun(results.length, `Generated 1 file:`, `Generated ${results.length} files`)}`\n    )\n\n    for (const { path } of results) {\n        logger.info(`\\t${path}`)\n    }\n\n    return results\n}\n\ntask(TASK_LZ_EXPORT_DEPLOYMENTS_TYPESCRIPT, 'Export deployments as TypeScript files', action)\n    .addParam(\n        'networks',\n        'List of comma-separated networks. If not provided, all networks will be deployed',\n        undefined,\n        types.csv,\n        true\n    )\n    .addParam(\n        'contracts',\n        'List of comma-separated contract names. If not provided, all contracts will be exported',\n        undefined,\n        types.csv,\n        true\n    )\n    .addParam('logLevel', 'Logging level. One of: error, warn, info, verbose, debug, silly', 'info', types.logLevel)\n"]}